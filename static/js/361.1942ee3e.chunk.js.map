{"version":3,"file":"static/js/361.1942ee3e.chunk.js","mappings":"gTAIaA,G,SAAQ,WAIjB,WAAYC,IAAa,eAErBC,QAAQC,IAAI,wBACZD,QAAQC,IAAI,kCAOdC,IAEEF,QAAQC,IAAI,mBAChB,CAdC,OAcA,+BAhBD,WAEA,KAAC,EAHgB,IAmBfC,EAAO,yCAAG,6GACKC,IAAU,KAAD,EAEd,OAFRC,EAAI,OACVJ,QAAQC,IAAIG,GACZC,EAAQD,GAAM,SAEOE,EAAgBF,GAAM,KAAD,EAGf,OAHrBG,EAAM,OACZP,QAAQC,IAAIM,GAENC,EAAQC,IAAa,UAErBC,EAAWF,EAAOD,EAAOI,OAAQJ,EAAOK,QAAQ,KAAD,GAErDC,EAAUL,EAAOJ,EAAMG,GAAQ,4CAEhC,kBAdY,mCAePJ,EAAO,yCAAG,6GACmBW,MAAM,+DAA+D,KAAD,EAA7E,OAAhBC,EAAgB,gBACCA,EAAiBC,OAAO,KAAD,EAKc,OALtDC,EAAQ,OACRC,EAAUD,EAASE,KAAI,SAAAC,GAAG,MAAK,CACnCC,IAAKD,EAAIE,iBACTC,WAAYH,EAAII,WACjB,IACAC,QAAO,SAAAL,GAAG,OAAgB,MAAXA,EAAIC,KAAiC,MAAlBD,EAAIG,UAAkB,IAAE,kBAEpDL,GAAO,2CACjB,kBAVY,mCAYPb,EAAO,yCAAG,WAAOD,GAAI,sEACRA,EAAKe,KAAI,SAAAO,GAAC,MAAK,CAC5BC,EAAGD,EAAEH,WACLK,EAAGF,EAAEL,IACN,IAUD,2CAED,gBAhBU,sCAkBPZ,EAAc,WAEhB,IAAMD,EAAQqB,EAAAA,MAQd,OALArB,EAAMsB,IAAID,EAAAA,IAAAA,MAAgB,CAACE,WAAY,CAAC,GAAIC,MAAO,EAAGC,SAAS,KAG/DzB,EAAMsB,IAAID,EAAAA,IAAAA,MAAgB,CAACG,MAAO,EAAGC,SAAS,KAEvCzB,CACT,EAGIF,EAAe,yCAAG,WAAOF,GAAI,+FAI1ByB,EAAAA,KAAQ,WAEbA,EAAAA,IAAAA,QAAgBzB,GAGhB,IAAMO,EAASP,EAAKe,KAAI,SAAAO,GAAC,OAAIA,EAAEH,UAAU,IACnCX,EAASR,EAAKe,KAAI,SAAAO,GAAC,OAAIA,EAAEL,GAAG,IAE5Ba,EAAcL,EAAAA,IAAYlB,EAAQ,CAACA,EAAOwB,OAAQ,IAClDC,EAAcP,EAAAA,IAAYjB,EAAQ,CAACA,EAAOuB,OAAQ,IAGlDE,EAAWH,EAAYI,MACvBC,EAAWL,EAAYM,MACvBC,EAAWL,EAAYE,MACvBI,EAAWN,EAAYI,MAK7B,MAAO,CACL7B,OAJuBuB,EAAYS,IAAIJ,GAAUK,IAAIP,EAASM,IAAIJ,IAKlE3B,OAJuBwB,EAAYO,IAAID,GAAUE,IAAIH,EAASE,IAAID,IAMlEL,SAAAA,EACAE,SAAAA,EACAE,SAAAA,EACAC,SAAAA,EAEJ,KAAE,2CACH,gBAlCoB,sCAoCdhC,EAAU,yCAAG,WAAOF,EAAOG,EAAQC,GAAM,sEAS9B,OAPhBJ,EAAMqC,QAAQ,CACZC,UAAWjB,EAAAA,IAAAA,OACXkB,KAAMlB,EAAAA,IAAAA,iBACNmB,QAAS,CAAC,SAGM,GACH,EAAE,EAAD,OAEHxC,EAAMyC,IAAItC,EAAQC,EAAQ,CACrCsC,UAJgB,GAKhBC,OAJa,EAKbC,SAAS,IAMR,KAAD,8EACH,gBArBgB,0CAuBXvC,EAAY,SAACL,EAAO6C,EAAWC,GACnC,IAAOjB,EAA0CiB,EAA1CjB,SAAUE,EAAgCe,EAAhCf,SAAUG,EAAsBY,EAAtBZ,SAAUD,EAAYa,EAAZb,SAKrC,EAAoBZ,EAAAA,KAAQ,WAE1B,IAAM0B,EAAK1B,EAAAA,IAAY,EAAG,EAAG,KACvB2B,EAAQhD,EAAMiD,QAAQF,EAAGG,QAAQ,CAAC,IAAK,KAEvCC,EAAWJ,EAAGK,IAAIvB,EAASM,IAAIJ,IAAWT,IAAIS,GAE9CsB,EAAcL,EAAMI,IAAInB,EAASE,IAAID,IAAWZ,IAAIY,GAG1D,MAAO,CAACiB,EAASG,WAAYD,EAAYC,WAC3C,IAAE,eAXKP,EAAE,KAAEC,EAAK,KAcQO,MAAMC,KAAKT,GAAIpC,KAAI,SAAC8C,EAAKC,GAC/C,MAAO,CAACvC,EAAGsC,EAAKrC,EAAG4B,EAAMU,GAC3B,IAEuBb,EAAUlC,KAAI,SAAAO,GAAC,MAAK,CACzCC,EAAGD,EAAEH,WAAYK,EAAGF,EAAEL,IACvB,GAYH,C","sources":["PART_06_Problem_Data_Model_Train_Validation/LAB_Web_03_MPGPrediction/index.ts"],"sourcesContent":["import * as tf from '@tensorflow/tfjs';\r\n// import * as tfvis from '@tensorflow/tfjs-vis';\r\nimport '@tensorflow/tfjs-backend-webgl';\r\n\r\nexport class Solution {\r\n    public destroy() {\r\n        \r\n    }\r\n    constructor(id: string) {\r\n    //  https://js.tensorflow.org/api/latest/\r\n        console.log(\"Let's learn TF JS !!\");\r\n        console.log(\"==============================\");\r\n\r\n      // const data  = await getData()\r\n\r\n      //   const model = createModel();\r\n      //   tfvis.show.modelSummary({name: 'Model Summary'}, model);\r\n\r\n      execute();\r\n\r\n        console.log('Playground done!');\r\n    }\r\n};\r\nconst execute = async () => {\r\n  const data = await getData();\r\n  console.log(data);\r\n  visData(data);\r\n\r\n  const tensor = await convertToTensor(data);\r\n  console.log(tensor)\r\n\r\n  const model = createModel()\r\n\r\n  await trainModel(model, tensor.inputs, tensor.labels);\r\n\r\n  testModel(model, data, tensor);\r\n\r\n}\r\nconst getData = async () => {\r\n    const carsDataResponse = await fetch('https://storage.googleapis.com/tfjs-tutorials/carsData.json');\r\n    const carsData = await carsDataResponse.json();\r\n    const cleaned = carsData.map(car => ({\r\n      mpg: car.Miles_per_Gallon,\r\n      horsepower: car.Horsepower,\r\n    }))\r\n    .filter(car => (car.mpg != null && car.horsepower != null));\r\n  \r\n    return cleaned;\r\n};\r\n\r\nconst visData = async (data) => {\r\n    const values = data.map(d => ({\r\n      x: d.horsepower,\r\n      y: d.mpg,\r\n    }));\r\n  \r\n    // tfvis.render.scatterplot(\r\n    //   {name: 'Horsepower v MPG'},\r\n    //   {values},\r\n    //   {\r\n    //     xLabel: 'Horsepower',\r\n    //     yLabel: 'MPG',\r\n    //     height: 300\r\n    //   }\r\n    // );\r\n  \r\n  }\r\n\r\nconst createModel = () => {\r\n    // Create a sequential model\r\n    const model = tf.sequential();\r\n  \r\n    // Add a single input layer\r\n    model.add(tf.layers.dense({inputShape: [1], units: 1, useBias: true}));\r\n  \r\n    // Add an output layer\r\n    model.add(tf.layers.dense({units: 1, useBias: true}));\r\n  \r\n    return model;\r\n  }\r\n\r\n\r\nconst convertToTensor = async (data) => {\r\n  // Wrapping these calculations in a tidy will dispose any\r\n  // intermediate tensors.\r\n\r\n  return tf.tidy(() => {\r\n    // Step 1. Shuffle the data\r\n    tf.util.shuffle(data);\r\n\r\n    // Step 2. Convert data to Tensor\r\n    const inputs = data.map(d => d.horsepower)\r\n    const labels = data.map(d => d.mpg);\r\n\r\n    const inputTensor = tf.tensor2d(inputs, [inputs.length, 1]);\r\n    const labelTensor = tf.tensor2d(labels, [labels.length, 1]);\r\n\r\n    //Step 3. Normalize the data to the range 0 - 1 using min-max scaling\r\n    const inputMax = inputTensor.max();\r\n    const inputMin = inputTensor.min();\r\n    const labelMax = labelTensor.max();\r\n    const labelMin = labelTensor.min();\r\n\r\n    const normalizedInputs = inputTensor.sub(inputMin).div(inputMax.sub(inputMin));\r\n    const normalizedLabels = labelTensor.sub(labelMin).div(labelMax.sub(labelMin));\r\n\r\n    return {\r\n      inputs: normalizedInputs,\r\n      labels: normalizedLabels,\r\n      // Return the min/max bounds so we can use them later.\r\n      inputMax,\r\n      inputMin,\r\n      labelMax,\r\n      labelMin,\r\n    }\r\n  });\r\n}\r\n\r\n const trainModel = async (model, inputs, labels) => {\r\n  // Prepare the model for training.\r\n  model.compile({\r\n    optimizer: tf.train.adam(),\r\n    loss: tf.losses.meanSquaredError,\r\n    metrics: ['mse'],\r\n  });\r\n\r\n  const batchSize = 32;\r\n  const epochs = 0;\r\n\r\n  return await model.fit(inputs, labels, {\r\n    batchSize,\r\n    epochs,\r\n    shuffle: true,\r\n    // callbacks: tfvis.show.fitCallbacks(\r\n    //   { name: 'Training Performance' },\r\n    //   ['loss', 'mse'],\r\n    //   { height: 200, callbacks: ['onEpochEnd'] }\r\n    // )\r\n  });\r\n}\r\n\r\nconst testModel = (model, inputData, normalizationData) => {\r\n  const {inputMax, inputMin, labelMin, labelMax} = normalizationData;\r\n\r\n  // Generate predictions for a uniform range of numbers between 0 and 1;\r\n  // We un-normalize the data by doing the inverse of the min-max scaling\r\n  // that we did earlier.\r\n  const [xs, preds] = tf.tidy(() => {\r\n\r\n    const xs = tf.linspace(0, 1, 100);\r\n    const preds = model.predict(xs.reshape([100, 1]));\r\n\r\n    const unNormXs = xs.mul(inputMax.sub(inputMin)).add(inputMin);\r\n\r\n    const unNormPreds = preds.mul(labelMax.sub(labelMin)).add(labelMin);\r\n\r\n    // Un-normalize the data\r\n    return [unNormXs.dataSync(), unNormPreds.dataSync()];\r\n  });\r\n\r\n\r\n  const predictedPoints = Array.from(xs).map((val, i) => {\r\n    return {x: val, y: preds[i]}\r\n  });\r\n\r\n  const originalPoints = inputData.map(d => ({\r\n    x: d.horsepower, y: d.mpg,\r\n  }));\r\n\r\n\r\n  // tfvis.render.scatterplot(\r\n  //   {name: 'Model Predictions vs Original Data'},\r\n  //   {values: [originalPoints, predictedPoints], series: ['original', 'predicted']},\r\n  //   {\r\n  //     xLabel: 'Horsepower',\r\n  //     yLabel: 'MPG',\r\n  //     height: 300\r\n  //   }\r\n  // );\r\n}"],"names":["Solution","id","console","log","execute","getData","data","visData","convertToTensor","tensor","model","createModel","trainModel","inputs","labels","testModel","fetch","carsDataResponse","json","carsData","cleaned","map","car","mpg","Miles_per_Gallon","horsepower","Horsepower","filter","d","x","y","tf","add","inputShape","units","useBias","inputTensor","length","labelTensor","inputMax","max","inputMin","min","labelMax","labelMin","sub","div","compile","optimizer","loss","metrics","fit","batchSize","epochs","shuffle","inputData","normalizationData","xs","preds","predict","reshape","unNormXs","mul","unNormPreds","dataSync","Array","from","val","i"],"sourceRoot":""}