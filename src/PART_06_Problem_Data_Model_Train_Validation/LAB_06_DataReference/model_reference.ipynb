{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# **Data in Design, AI for Urban Data and Visualization**\n",
    "\n",
    "#### Data, Design Computation, Artificial Intelligence, Visualization, Harvard GSD\n",
    "\n",
    "\n",
    "**KEYWORD:**\n",
    "Vector, Raster, Urban Data, GIS, Data Processing, Data Mining, Machine Learning, Artificial Intelligence, Visualization, Mapping, Design Decision-Making\n",
    "\n",
    "-----\n",
    "\n",
    "#### Instructor : NJ Namju Lee / nj.namju@gmail.com  \n",
    "###### * Linkedin - https://www.linkedin.com/in/nj-namju-lee-926b3252/    * Git - https://github.com/NamjuLee  \n",
    "\n",
    "###### * Web - http://www.njstudio.co.kr                                  * Lab - http://www.njslab.com/NJSLabCore/  \n",
    "\n",
    "###### * Video(English) - https://www.youtube.com/c/njnamjulee            * Writing(English) - https://medium.com/@nj-namju  \n",
    "\n",
    "###### * Video(Korean) - https://www.youtube.com/c/CodeforDesign          * Writing(Korean) - https://brunch.co.kr/@njnamju  \n",
    "-----"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn import datasets\n",
    "import numpy as np\n",
    "import pandas as pd"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_boston():\n",
    "    boston_raw_data = datasets.load_boston()\n",
    "    # print(boston_raw_data)\n",
    "    X_boston_data = pd.DataFrame(boston_raw_data.data)\n",
    "    y_boston_data = pd.DataFrame(boston_raw_data.target)\n",
    "    feature_boston_data = boston_raw_data.feature_names\n",
    "    feature_boston_data = np.concatenate([feature_boston_data, np.array(['targets'])])\n",
    "    df_boston = pd.concat([X_boston_data,y_boston_data], axis=1)\n",
    "    df_boston.columns = feature_boston_data\n",
    "    return df_boston\n",
    "def load_diabetes():\n",
    "    raw_data = datasets.load_diabetes()\n",
    "    X_data = pd.DataFrame(raw_data.data)\n",
    "    y_data = pd.DataFrame(raw_data.target)\n",
    "    feature = raw_data.feature_names\n",
    "    feature = np.concatenate([feature, np.array(['targets'])])\n",
    "    df = pd.concat([X_data,y_data], axis=1)\n",
    "    df.columns = feature\n",
    "    return df"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "classification"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_breast_cancer():\n",
    "    raw_data = datasets.load_breast_cancer()\n",
    "    X_data = pd.DataFrame(raw_data.data)\n",
    "    y_data = pd.DataFrame(raw_data.target)\n",
    "    feature = raw_data.feature_names\n",
    "    feature = np.concatenate([feature, np.array(['targets'])])\n",
    "    df = pd.concat([X_data,y_data], axis=1)\n",
    "    df.columns = feature\n",
    "    return df\n",
    "def load_iris():\n",
    "    raw_data = datasets.load_iris()\n",
    "    X_data = pd.DataFrame(raw_data.data)\n",
    "    y_data = pd.DataFrame(raw_data.target)\n",
    "    feature = raw_data.feature_names\n",
    "    feature = np.concatenate([feature, np.array(['targets'])])\n",
    "    df = pd.concat([X_data,y_data], axis=1)\n",
    "    df.columns = feature\n",
    "    return df\n",
    "def load_wine():\n",
    "    raw_data = datasets.load_wine()\n",
    "    X_data = pd.DataFrame(raw_data.data)\n",
    "    y_data = pd.DataFrame(raw_data.target)\n",
    "    feature = raw_data.feature_names\n",
    "    feature = np.concatenate([feature, np.array(['targets'])])\n",
    "    df = pd.concat([X_data,y_data], axis=1)\n",
    "    df.columns = feature\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.preprocessing import Normalizer\n",
    "from sklearn.preprocessing import RobustScaler\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.preprocessing import MaxAbsScaler\n",
    "from enum import Enum\n",
    "\n",
    "TYPE_SCALER_LIST = ('NONE','StandardScaler', 'Normalizer', 'RobustScaler', 'MinMaxScaler', 'MaxAbsScaler')\n",
    "TYPE_SCALER = Enum('TYPE_SCALER', TYPE_SCALER_LIST)\n",
    "\n",
    "def scalers(X_train, x_test, type=TYPE_SCALER.StandardScaler ):\n",
    "    scaler = StandardScaler()\n",
    "    if(type == TYPE_SCALER.RobustScaler):\n",
    "         scaler = RobustScaler()\n",
    "    elif(type == TYPE_SCALER.Normalizer):\n",
    "         scaler = Normalizer()\n",
    "    elif(type == TYPE_SCALER.MinMaxScaler):\n",
    "         scaler = MinMaxScaler()\n",
    "    elif(type == TYPE_SCALER.MaxAbsScaler):\n",
    "         scaler = MaxAbsScaler()\n",
    "    scaler.fit(X_train)\n",
    "    X_train = scaler.transform(X_train)\n",
    "    x_test  = scaler.transform(x_test)\n",
    "    return [X_train, x_test, scaler ]\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "def getDatasetFromDF(df, testSize=0.3):\n",
    "     np.random.seed(2222)  \n",
    "     array = df.to_numpy()\n",
    "     np.random.shuffle(array)\n",
    "     X = array[:,:-1]\n",
    "     y = array[:,-1:].flatten()\n",
    "     X_train, X_test, y_train, y_test = train_test_split(X,y, test_size=testSize, random_state=2)\n",
    "     return [X_train, X_test, y_train, y_test]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LinearRegression \n",
    "from sklearn.linear_model import Ridge\n",
    "from sklearn.linear_model import Lasso\n",
    "from sklearn.linear_model import ElasticNet\n",
    "\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from sklearn.metrics import r2_score\n",
    "\n",
    "TYPE_Regression_LIST = ('LinearRegression', 'Ridge', 'Lasso', 'ElasticNet')\n",
    "TYPE_Regression = Enum('TYPE_Regression', TYPE_Regression_LIST)\n",
    "\n",
    "class Regression_Model:\n",
    "    def __init__(self, X_train, y_train, X_test, y_test, n = 3):\n",
    "        self.X_train = X_train\n",
    "        self.y_train = y_train\n",
    "        self.X_test = X_test\n",
    "        self.y_test = y_test\n",
    "        self.n = n\n",
    "        self.predResult = None\n",
    "        self.scaler = None\n",
    "    def scale(self, type=TYPE_SCALER.NONE):\n",
    "        if type != TYPE_SCALER.NONE:\n",
    "            X_train_scaled, X_test_scaled, scaler = scalers(self.X_train, self.X_test, type)\n",
    "            self.X_train = X_train_scaled\n",
    "            self.X_test = X_test_scaled\n",
    "            self.scaler = scaler\n",
    "    def fit(self, type=TYPE_Regression.LinearRegression):\n",
    "        self.TYPE = TYPE_Regression\n",
    "        self.model = LinearRegression()\n",
    "        if(type == TYPE_Regression.Ridge):\n",
    "            self.model = Ridge()\n",
    "        elif(type == TYPE_Regression.Lasso):\n",
    "            self.model = Lasso()\n",
    "        elif(type == TYPE_Regression.ElasticNet):\n",
    "            self.model = ElasticNet()\n",
    "        self.model.fit(self.X_train, self.y_train)\n",
    "        self.score()\n",
    "    def predict(self, X_test):\n",
    "        return self.model.predict(X_test)\n",
    "    def score(self):\n",
    "        self.predResult = self.model.predict(self.X_test)\n",
    "        R2 = r2_score(self.y_test, self.predResult)\n",
    "        MSE  = mean_squared_error(self.y_test, self.predResult)\n",
    "        print(str(self.TYPE), ', R2:', R2, \" ,\", \"MSE: \", MSE )\n",
    "        return [R2, MSE]\n",
    "    def coef(self):\n",
    "        return self.model.coef_\n",
    "    def intercept(self):\n",
    "        return self.model.intercept_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\namju\\miniconda3\\envs\\tf-gpu-2022\\lib\\site-packages\\sklearn\\utils\\deprecation.py:87: FutureWarning: Function load_boston is deprecated; `load_boston` is deprecated in 1.0 and will be removed in 1.2.\n",
      "\n",
      "    The Boston housing prices dataset has an ethical problem. You can refer to\n",
      "    the documentation of this function for further details.\n",
      "\n",
      "    The scikit-learn maintainers therefore strongly discourage the use of this\n",
      "    dataset unless the purpose of the code is to study and educate about\n",
      "    ethical issues in data science and machine learning.\n",
      "\n",
      "    In this special case, you can fetch the dataset from the original\n",
      "    source::\n",
      "\n",
      "        import pandas as pd\n",
      "        import numpy as np\n",
      "\n",
      "\n",
      "        data_url = \"http://lib.stat.cmu.edu/datasets/boston\"\n",
      "        raw_df = pd.read_csv(data_url, sep=\"\\s+\", skiprows=22, header=None)\n",
      "        data = np.hstack([raw_df.values[::2, :], raw_df.values[1::2, :2]])\n",
      "        target = raw_df.values[1::2, 2]\n",
      "\n",
      "    Alternative datasets include the California housing dataset (i.e.\n",
      "    :func:`~sklearn.datasets.fetch_california_housing`) and the Ames housing\n",
      "    dataset. You can load the datasets as follows::\n",
      "\n",
      "        from sklearn.datasets import fetch_california_housing\n",
      "        housing = fetch_california_housing()\n",
      "\n",
      "    for the California housing dataset and::\n",
      "\n",
      "        from sklearn.datasets import fetch_openml\n",
      "        housing = fetch_openml(name=\"house_prices\", as_frame=True)\n",
      "\n",
      "    for the Ames housing dataset.\n",
      "    \n",
      "  warnings.warn(msg, category=FutureWarning)\n"
     ]
    }
   ],
   "source": [
    "df = load_boston()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<enum 'TYPE_Regression'> , R2: 0.7076049962856348  , MSE:  22.242948469869333\n",
      "[-1.02948928  1.13277315  0.04789631  0.73978974 -2.45927567  2.78782208\n",
      "  0.31512775 -3.43778829  3.25288152 -2.22342167 -2.36051691  1.02555048\n",
      " -3.6890774 ] 22.87881355932204\n"
     ]
    }
   ],
   "source": [
    "X_train, X_test, y_train, y_test = getDatasetFromDF(df)\n",
    "\n",
    "RegressionModel = Regression_Model(X_train, y_train, X_test, y_test)\n",
    "RegressionModel.scale(TYPE_Regression.LinearRegression)\n",
    "RegressionModel.fit()\n",
    "print(RegressionModel.coef(), RegressionModel.intercept())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<enum 'TYPE_Regression'> , R2: 0.4882490127228074  , MSE:  3211.6934760769536\n",
      "[ -3.20741266  -7.64938     26.4608481   16.05522177 -33.00882382\n",
      "  18.29955666   4.94760592   8.68017214  34.43006948   0.32712675] 150.5566343042071\n"
     ]
    }
   ],
   "source": [
    "df = load_diabetes()\n",
    "X_train, X_test, y_train, y_test = getDatasetFromDF(df)\n",
    "\n",
    "RegressionModel = Regression_Model(X_train, y_train, X_test, y_test)\n",
    "RegressionModel.scale(TYPE_Regression.Ridge)\n",
    "RegressionModel.fit()\n",
    "print(RegressionModel.coef(), RegressionModel.intercept())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.metrics import classification_report\n",
    "from sklearn.metrics import precision_score\n",
    "\n",
    "TYPE_Penalty_LIST = ('NONE', 'l2', 'l1', 'elasticnet')\n",
    "TYPE_Penalty = Enum('TYPE_Penalty', TYPE_Penalty_LIST)\n",
    "\n",
    "class Logistic_Regression_Model:\n",
    "    def __init__(self, X_train, y_train, X_test, y_test):\n",
    "        self.X_train = X_train\n",
    "        self.y_train = y_train\n",
    "        self.X_test = X_test\n",
    "        self.y_test = y_test\n",
    "        self.predResult = None\n",
    "        self.scaler = None\n",
    "    def scale(self, type=TYPE_SCALER.NONE):\n",
    "        if type != TYPE_SCALER.NONE:\n",
    "            X_train_scaled, X_test_scaled, scaler = scalers(self.X_train, self.X_test, type)\n",
    "            self.X_train = X_train_scaled\n",
    "            self.X_test = X_test_scaled\n",
    "            self.scaler = scaler\n",
    "    def fit(self, type = TYPE_Penalty.l1):\n",
    "        self.model = LogisticRegression(penalty='none')\n",
    "        if(type == TYPE_Penalty.NONE):\n",
    "            self.model = LogisticRegression(penalty='none')\n",
    "        elif(type == TYPE_Penalty.l2):\n",
    "            self.model = LogisticRegression(penalty='l2')\n",
    "        elif(type == TYPE_Penalty.elasticnet):\n",
    "            self.model = LogisticRegression(penalty='elasticnet')\n",
    "        self.model.fit(self.X_train, self.y_train)\n",
    "        self.score()\n",
    "    def predict(self, X_test):\n",
    "        return self.model.predict(X_test)\n",
    "    def predictProba(self, X_test):\n",
    "        return self.model.predict_proba(X_test)\n",
    "    def score(self):\n",
    "        self.predResult = self.model.predict(self.X_test)\n",
    "        accuracy = precision_score(self.y_test, self.predResult)\n",
    "        print(accuracy)\n",
    "        return accuracy\n",
    "    def confusionMatrix(self):\n",
    "        return confusion_matrix(self.y_test, self.predResult)\n",
    "    def classificationReport(self):\n",
    "        return classification_report(self.y_test, self.predResult)\n",
    "    def coef(self):\n",
    "        return self.model.coef_\n",
    "    def intercept(self):\n",
    "        return self.model.intercept_\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.9626168224299065\n",
      "[[0.00000000e+000 1.00000000e+000]\n",
      " [0.00000000e+000 1.00000000e+000]\n",
      " [0.00000000e+000 1.00000000e+000]\n",
      " [0.00000000e+000 1.00000000e+000]\n",
      " [0.00000000e+000 1.00000000e+000]\n",
      " [0.00000000e+000 1.00000000e+000]\n",
      " [0.00000000e+000 1.00000000e+000]\n",
      " [0.00000000e+000 1.00000000e+000]\n",
      " [0.00000000e+000 1.00000000e+000]\n",
      " [0.00000000e+000 1.00000000e+000]\n",
      " [0.00000000e+000 1.00000000e+000]\n",
      " [1.00000000e+000 1.06860955e-167]\n",
      " [0.00000000e+000 1.00000000e+000]\n",
      " [1.00000000e+000 0.00000000e+000]\n",
      " [1.00000000e+000 0.00000000e+000]\n",
      " [1.00000000e+000 0.00000000e+000]\n",
      " [0.00000000e+000 1.00000000e+000]\n",
      " [0.00000000e+000 1.00000000e+000]\n",
      " [0.00000000e+000 1.00000000e+000]\n",
      " [0.00000000e+000 1.00000000e+000]\n",
      " [0.00000000e+000 1.00000000e+000]\n",
      " [0.00000000e+000 1.00000000e+000]\n",
      " [0.00000000e+000 1.00000000e+000]\n",
      " [1.00000000e+000 0.00000000e+000]\n",
      " [1.00000000e+000 0.00000000e+000]\n",
      " [0.00000000e+000 1.00000000e+000]\n",
      " [0.00000000e+000 1.00000000e+000]\n",
      " [0.00000000e+000 1.00000000e+000]\n",
      " [1.00000000e+000 0.00000000e+000]\n",
      " [1.00000000e+000 0.00000000e+000]\n",
      " [0.00000000e+000 1.00000000e+000]\n",
      " [0.00000000e+000 1.00000000e+000]\n",
      " [1.00000000e+000 0.00000000e+000]\n",
      " [1.00000000e+000 0.00000000e+000]\n",
      " [0.00000000e+000 1.00000000e+000]\n",
      " [0.00000000e+000 1.00000000e+000]\n",
      " [1.00000000e+000 0.00000000e+000]\n",
      " [0.00000000e+000 1.00000000e+000]\n",
      " [0.00000000e+000 1.00000000e+000]\n",
      " [1.00000000e+000 0.00000000e+000]\n",
      " [1.00000000e+000 0.00000000e+000]\n",
      " [1.00000000e+000 2.05210108e-021]\n",
      " [1.00000000e+000 0.00000000e+000]\n",
      " [1.00000000e+000 0.00000000e+000]\n",
      " [0.00000000e+000 1.00000000e+000]\n",
      " [1.00000000e+000 0.00000000e+000]\n",
      " [1.00000000e+000 0.00000000e+000]\n",
      " [1.00000000e+000 1.23756477e-057]\n",
      " [0.00000000e+000 1.00000000e+000]\n",
      " [1.00000000e+000 0.00000000e+000]\n",
      " [0.00000000e+000 1.00000000e+000]\n",
      " [1.00000000e+000 0.00000000e+000]\n",
      " [0.00000000e+000 1.00000000e+000]\n",
      " [1.00000000e+000 0.00000000e+000]\n",
      " [0.00000000e+000 1.00000000e+000]\n",
      " [0.00000000e+000 1.00000000e+000]\n",
      " [1.00000000e+000 0.00000000e+000]\n",
      " [0.00000000e+000 1.00000000e+000]\n",
      " [0.00000000e+000 1.00000000e+000]\n",
      " [0.00000000e+000 1.00000000e+000]\n",
      " [0.00000000e+000 1.00000000e+000]\n",
      " [0.00000000e+000 1.00000000e+000]\n",
      " [0.00000000e+000 1.00000000e+000]\n",
      " [1.00000000e+000 0.00000000e+000]\n",
      " [1.00000000e+000 0.00000000e+000]\n",
      " [0.00000000e+000 1.00000000e+000]\n",
      " [0.00000000e+000 1.00000000e+000]\n",
      " [1.00000000e+000 0.00000000e+000]\n",
      " [0.00000000e+000 1.00000000e+000]\n",
      " [1.00000000e+000 1.84223938e-106]\n",
      " [1.00000000e+000 0.00000000e+000]\n",
      " [1.00000000e+000 0.00000000e+000]\n",
      " [0.00000000e+000 1.00000000e+000]\n",
      " [0.00000000e+000 1.00000000e+000]\n",
      " [0.00000000e+000 1.00000000e+000]\n",
      " [1.00000000e+000 0.00000000e+000]\n",
      " [0.00000000e+000 1.00000000e+000]\n",
      " [0.00000000e+000 1.00000000e+000]\n",
      " [1.00000000e+000 0.00000000e+000]\n",
      " [1.00000000e+000 0.00000000e+000]\n",
      " [0.00000000e+000 1.00000000e+000]\n",
      " [0.00000000e+000 1.00000000e+000]\n",
      " [1.00000000e+000 0.00000000e+000]\n",
      " [0.00000000e+000 1.00000000e+000]\n",
      " [0.00000000e+000 1.00000000e+000]\n",
      " [1.00000000e+000 0.00000000e+000]\n",
      " [1.00000000e+000 0.00000000e+000]\n",
      " [0.00000000e+000 1.00000000e+000]\n",
      " [0.00000000e+000 1.00000000e+000]\n",
      " [1.00000000e+000 0.00000000e+000]\n",
      " [0.00000000e+000 1.00000000e+000]\n",
      " [0.00000000e+000 1.00000000e+000]\n",
      " [0.00000000e+000 1.00000000e+000]\n",
      " [0.00000000e+000 1.00000000e+000]\n",
      " [1.00000000e+000 0.00000000e+000]\n",
      " [1.00000000e+000 0.00000000e+000]\n",
      " [0.00000000e+000 1.00000000e+000]\n",
      " [0.00000000e+000 1.00000000e+000]\n",
      " [0.00000000e+000 1.00000000e+000]\n",
      " [1.00000000e+000 0.00000000e+000]\n",
      " [1.00000000e+000 0.00000000e+000]\n",
      " [0.00000000e+000 1.00000000e+000]\n",
      " [0.00000000e+000 1.00000000e+000]\n",
      " [0.00000000e+000 1.00000000e+000]\n",
      " [1.00000000e+000 5.75310863e-091]\n",
      " [0.00000000e+000 1.00000000e+000]\n",
      " [0.00000000e+000 1.00000000e+000]\n",
      " [0.00000000e+000 1.00000000e+000]\n",
      " [0.00000000e+000 1.00000000e+000]\n",
      " [0.00000000e+000 1.00000000e+000]\n",
      " [0.00000000e+000 1.00000000e+000]\n",
      " [0.00000000e+000 1.00000000e+000]\n",
      " [8.09217056e-007 9.99999191e-001]\n",
      " [1.00000000e+000 0.00000000e+000]\n",
      " [0.00000000e+000 1.00000000e+000]\n",
      " [0.00000000e+000 1.00000000e+000]\n",
      " [0.00000000e+000 1.00000000e+000]\n",
      " [0.00000000e+000 1.00000000e+000]\n",
      " [1.00000000e+000 0.00000000e+000]\n",
      " [0.00000000e+000 1.00000000e+000]\n",
      " [1.00000000e+000 0.00000000e+000]\n",
      " [0.00000000e+000 1.00000000e+000]\n",
      " [0.00000000e+000 1.00000000e+000]\n",
      " [0.00000000e+000 1.00000000e+000]\n",
      " [0.00000000e+000 1.00000000e+000]\n",
      " [0.00000000e+000 1.00000000e+000]\n",
      " [1.00000000e+000 0.00000000e+000]\n",
      " [0.00000000e+000 1.00000000e+000]\n",
      " [0.00000000e+000 1.00000000e+000]\n",
      " [0.00000000e+000 1.00000000e+000]\n",
      " [1.00000000e+000 0.00000000e+000]\n",
      " [0.00000000e+000 1.00000000e+000]\n",
      " [0.00000000e+000 1.00000000e+000]\n",
      " [1.00000000e+000 0.00000000e+000]\n",
      " [1.00000000e+000 0.00000000e+000]\n",
      " [0.00000000e+000 1.00000000e+000]\n",
      " [0.00000000e+000 1.00000000e+000]\n",
      " [1.00000000e+000 0.00000000e+000]\n",
      " [1.00000000e+000 2.32216639e-265]\n",
      " [1.00000000e+000 0.00000000e+000]\n",
      " [1.00000000e+000 3.90037908e-055]\n",
      " [1.00000000e+000 0.00000000e+000]\n",
      " [0.00000000e+000 1.00000000e+000]\n",
      " [1.00000000e+000 0.00000000e+000]\n",
      " [0.00000000e+000 1.00000000e+000]\n",
      " [1.00000000e+000 0.00000000e+000]\n",
      " [0.00000000e+000 1.00000000e+000]\n",
      " [0.00000000e+000 1.00000000e+000]\n",
      " [0.00000000e+000 1.00000000e+000]\n",
      " [0.00000000e+000 1.00000000e+000]\n",
      " [0.00000000e+000 1.00000000e+000]\n",
      " [0.00000000e+000 1.00000000e+000]\n",
      " [1.00000000e+000 7.00225563e-061]\n",
      " [0.00000000e+000 1.00000000e+000]\n",
      " [1.00000000e+000 0.00000000e+000]\n",
      " [1.00000000e+000 0.00000000e+000]\n",
      " [1.00000000e+000 0.00000000e+000]\n",
      " [0.00000000e+000 1.00000000e+000]\n",
      " [1.00000000e+000 0.00000000e+000]\n",
      " [0.00000000e+000 1.00000000e+000]\n",
      " [0.00000000e+000 1.00000000e+000]\n",
      " [0.00000000e+000 1.00000000e+000]\n",
      " [1.00000000e+000 0.00000000e+000]\n",
      " [1.00000000e+000 0.00000000e+000]\n",
      " [0.00000000e+000 1.00000000e+000]\n",
      " [0.00000000e+000 1.00000000e+000]\n",
      " [0.00000000e+000 1.00000000e+000]\n",
      " [0.00000000e+000 1.00000000e+000]\n",
      " [0.00000000e+000 1.00000000e+000]\n",
      " [1.00000000e+000 0.00000000e+000]\n",
      " [1.00000000e+000 0.00000000e+000]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.89      0.93      0.91        61\n",
      "         1.0       0.96      0.94      0.95       110\n",
      "\n",
      "    accuracy                           0.94       171\n",
      "   macro avg       0.93      0.94      0.93       171\n",
      "weighted avg       0.94      0.94      0.94       171\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df = load_breast_cancer()\n",
    "X_train, X_test, y_train, y_test = getDatasetFromDF(df)\n",
    "\n",
    "LRModel = Logistic_Regression_Model(X_train, y_train, X_test, y_test)\n",
    "LRModel.scale(TYPE_SCALER.StandardScaler)\n",
    "LRModel.fit(TYPE_Penalty.l1)\n",
    "print(LRModel.predictProba(LRModel.X_test))\n",
    "print(LRModel.classificationReport())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "tf-gpu-2022",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "72bc0f943a863b7fcc9ff0d11405a78faecbd3bfafd8f122065908abfcb424a6"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
