{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# **Data in Design, AI for Urban Data and Visualization**\n",
    "\n",
    "#### Data, Design Computation, Artificial Intelligence, Visualization, Harvard GSD\n",
    "\n",
    "\n",
    "**KEYWORD:**\n",
    "Vector, Raster, Urban Data, GIS, Data Processing, Data Mining, Machine Learning, Artificial Intelligence, Visualization, Mapping, Design Decision-Making\n",
    "\n",
    "-----\n",
    "\n",
    "#### Instructor : NJ Namju Lee / nj.namju@gmail.com  \n",
    "###### * Linkedin - https://www.linkedin.com/in/nj-namju-lee-926b3252/    * Git - https://github.com/NamjuLee  \n",
    "\n",
    "###### * Web - http://www.njstudio.co.kr                                  * Lab - http://www.njslab.com/NJSLabCore/  \n",
    "\n",
    "###### * Video(English) - https://www.youtube.com/c/njnamjulee            * Writing(English) - https://medium.com/@nj-namju  \n",
    "\n",
    "###### * Video(Korean) - https://www.youtube.com/c/CodeforDesign          * Writing(Korean) - https://brunch.co.kr/@njnamju  \n",
    "-----"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### AI / ML for designers, Computational Design Class\n",
    "### Smart Drawing: Vector and Raster data\n",
    "NJ Namju Lee / nj.namju@gmail.com"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 02 Vector Data Pre Processing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "def getNumpyLoadTxt(pathFileName):\n",
    "\treturn np.loadtxt( pathFileName, delimiter=',', skiprows=1)\n",
    "def SaveArrayViaNumpy(path, data):\n",
    "    npd = np.asarray(data)\n",
    "    np.savetxt(path, npd, delimiter=\",\")\n",
    "    print('done for save!')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# data pre processing from CSV to numpy mat\n",
    "def MergeMatrixBasedOnSameClass(numpyList, classID):\n",
    "    numpyMat = numpyList[0]\n",
    "    for i in range(1, len(numpyList)):\n",
    "        numpyMat = np.concatenate((numpyMat, numpyList[i]), axis=0)\n",
    "    theShape = numpyMat.shape\n",
    "    numpyMat = np.insert(numpyMat, theShape[1], classID, axis=1)\n",
    "    return numpyMat\n",
    "def GetNumpyByShuffe(d):\n",
    "    np.random.shuffle(d)\n",
    "    return d\n",
    "def PreProcessRawCSV(d):\n",
    "    npMatList = []\n",
    "    for i in range(len(d)):\n",
    "        mergedD = MergeMatrixBasedOnSameClass(d[i], i)\n",
    "        npMatList.append(mergedD)\n",
    "    npMatAll = npMatList[0]\n",
    "    for i in range(1,len( npMatList)):\n",
    "        npMatAll = np.concatenate((npMatAll, npMatList[i]), axis=0)\n",
    "    return npMatAll\n",
    "def DataPreProcessing(d):\n",
    "    npMatAll = PreProcessRawCSV(d)\n",
    "    npData = GetNumpyByShuffe(npMatAll)\n",
    "    trainLength =  npData.shape[1]-1\n",
    "    XMat = npData[:,0:trainLength]\n",
    "    yMat = npData[:,trainLength]\n",
    "    return [XMat,yMat]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "circleRawBoth = []\n",
    "circleRawBoth.append(getNumpyLoadTxt('./data/vector/circleCSV/circle_01_DotArrayForTrainOrigin.csv'))\n",
    "circleRawBoth.append(getNumpyLoadTxt('./data/vector/circleCSV/circle_01_DotArrayForTrainSimplify.csv'))\n",
    "\n",
    "arrowRawBoth = []\n",
    "arrowRawBoth.append(getNumpyLoadTxt('./data/vector/arrowCSV/arrow_01_DotArrayForTrainOrigin.csv'))\n",
    "arrowRawBoth.append(getNumpyLoadTxt('./data/vector/arrowCSV/arrow_01_DotArrayForTrainSimplify.csv'))\n",
    "\n",
    "rectangleRawBoth = []\n",
    "rectangleRawBoth.append(getNumpyLoadTxt('./data/vector/rectangleCSV/rectangle_01_DotArrayForTrainOrigin.csv'))\n",
    "rectangleRawBoth.append(getNumpyLoadTxt('./data/vector/rectangleCSV/rectangle_01_DotArrayForTrainSimplify.csv'))\n",
    "\n",
    "textRawBoth = []\n",
    "textRawBoth.append(getNumpyLoadTxt('./data/vector/textCSV/text_01_DotArrayForTrainOrigin.csv'))\n",
    "textRawBoth.append(getNumpyLoadTxt('./data/vector/textCSV/text_01_DotArrayForTrainSimplify.csv'))\n",
    "\n",
    "trainRawBoth = [circleRawBoth,arrowRawBoth,rectangleRawBoth, textRawBoth]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "circleRawOrigin = []\n",
    "circleRawOrigin.append(getNumpyLoadTxt('./data/vector/circleCSV/circle_01_DotArrayForTrainOrigin.csv'))\n",
    "\n",
    "arrowRawOrigin = []\n",
    "arrowRawOrigin.append(getNumpyLoadTxt('./data/vector/arrowCSV/arrow_01_DotArrayForTrainOrigin.csv'))\n",
    "\n",
    "rectangleRawOrigin = []\n",
    "rectangleRawOrigin.append(getNumpyLoadTxt('./data/vector/rectangleCSV/rectangle_01_DotArrayForTrainOrigin.csv'))\n",
    "\n",
    "textRawOrigin = []\n",
    "textRawOrigin.append(getNumpyLoadTxt('./data/vector/textCSV/text_01_DotArrayForTrainOrigin.csv'))\n",
    "\n",
    "trainRawOrigin = [circleRawOrigin,arrowRawOrigin,rectangleRawOrigin, textRawOrigin]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "circleRawSimplify = []\n",
    "circleRawSimplify.append(getNumpyLoadTxt('./data/vector/circleCSV/circle_01_DotArrayForTrainSimplify.csv'))\n",
    "\n",
    "arrowRawSimplify = []\n",
    "arrowRawSimplify.append(getNumpyLoadTxt('./data/vector/arrowCSV/arrow_01_DotArrayForTrainSimplify.csv'))\n",
    "\n",
    "rectangleRawSimplify = []\n",
    "rectangleRawSimplify.append(getNumpyLoadTxt('./data/vector/rectangleCSV/rectangle_01_DotArrayForTrainSimplify.csv'))\n",
    "\n",
    "textRawSimplify = []\n",
    "textRawSimplify.append(getNumpyLoadTxt('./data/vector/textCSV/text_01_DotArrayForTrainSimplify.csv'))\n",
    "\n",
    "trainRawSimplify = [circleRawSimplify,arrowRawSimplify,rectangleRawSimplify, textRawSimplify]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "# trainDATA = [trainRawOrigin,trainRawSimplify,trainRawBoth]\n",
    "trainDATA = [trainRawOrigin]       "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "done for save!\n"
     ]
    }
   ],
   "source": [
    "csv = PreProcessRawCSV(trainDATA[0])\n",
    "SaveArrayViaNumpy(\"./data/vector/dummy_smartDrawingTrainData.csv\", csv)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "def OpenJson(path): \n",
    "    json_file = open(path , 'r')\n",
    "    json_str = json_file.read()\n",
    "    json_data = json.loads(json_str)\n",
    "    return json_data\n",
    "def GetListByShuffle(d):\n",
    "    from random import shuffle\n",
    "    shuffle(d)\n",
    "    return d\n",
    "def SaveArrayNumpy(path, data):\n",
    "    npd = np.asarray(data)\n",
    "    np.savetxt(path, npd, delimiter=\",\")\n",
    "    print('done for save!')\n",
    "def SplitData(d, classID):\n",
    "    outDot = []\n",
    "    outpos = []\n",
    "    index = 0\n",
    "    for i in d:\n",
    "        if(index % 2 == 0):\n",
    "            temp = [];\n",
    "            for j in d[i]:\n",
    "                temp.append(j)\n",
    "            temp.append(classID);\n",
    "            outDot.append(temp);\n",
    "        else:\n",
    "            temp = [];\n",
    "            for j in d[i]:\n",
    "                temp.append(j)\n",
    "            temp.append(classID);\n",
    "            outpos.append(temp);\n",
    "        index+=1\n",
    "    return outDot, outpos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "trainDataRaw = []\n",
    "trainDataRaw.append(OpenJson('./data/vector/TrainDataForCircle.json'))\n",
    "trainDataRaw.append(OpenJson('./data/vector/TrainDataForRect.json'))\n",
    "trainDataRaw.append(OpenJson('./data/vector/TrainDataForTri.json'))\n",
    "trainDataRaw.append(OpenJson('./data/vector/TrainDataHexagon.json'))\n",
    "trainDataRaw.append(OpenJson('./data/vector/TrainDataRandom.json'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "trainDataBeforeProcessing = []\n",
    "\n",
    "for i in range(len(trainDataRaw)):\n",
    "    outD, outPos= SplitData(trainDataRaw[i],i)\n",
    "    for j in outD:   \n",
    "        trainDataBeforeProcessing.append(j)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "done for save!\n"
     ]
    }
   ],
   "source": [
    "\n",
    "trainDataBeforeProcessing = GetListByShuffle(trainDataBeforeProcessing)\n",
    "SaveArrayNumpy(\"./data/vector/dummy_dataTrain.csv\", trainDataBeforeProcessing)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "npData = np.asarray(trainDataBeforeProcessing)\n",
    "npData.shape\n",
    "\n",
    "XMat = npData[:,range(npData.shape[1]-1)]\n",
    "yMat = npData[:,[npData.shape[1]-1]]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "XTrain = XMat[0:200]\n",
    "XTest = XMat[200:]\n",
    "\n",
    "yTrain = yMat[0:200]\n",
    "yTest = yMat[200:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "done for save!\n"
     ]
    }
   ],
   "source": [
    "trainDataRaw = []\n",
    "trainDataRaw.append(OpenJson('data/vector/TrainDataForCircle.json'))\n",
    "trainDataRaw.append(OpenJson('data/vector/TrainDataForRect.json'))\n",
    "trainDataRaw.append(OpenJson('data/vector/TrainDataForTri.json'))\n",
    "trainDataRaw.append(OpenJson('data/vector/TrainDataHexagon.json'))\n",
    "\n",
    "trainDataBeforeProcessing = []\n",
    "\n",
    "for i in range(len(trainDataRaw)):\n",
    "    outD, outPos= SplitData(trainDataRaw[i],i)\n",
    "    for j in outD:   \n",
    "        trainDataBeforeProcessing.append(j)\n",
    "trainDataBeforeProcessing = GetListByShuffle(trainDataBeforeProcessing)\n",
    "npData = np.asarray(trainDataBeforeProcessing)\n",
    "SaveArrayNumpy(\"./data/vector/dummy_dataTrainOnly4Class.csv\", trainDataBeforeProcessing)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "tf-gpu-2022",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12 (main, Apr  4 2022, 05:22:27) [MSC v.1916 64 bit (AMD64)]"
  },
  "vscode": {
   "interpreter": {
    "hash": "72bc0f943a863b7fcc9ff0d11405a78faecbd3bfafd8f122065908abfcb424a6"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
