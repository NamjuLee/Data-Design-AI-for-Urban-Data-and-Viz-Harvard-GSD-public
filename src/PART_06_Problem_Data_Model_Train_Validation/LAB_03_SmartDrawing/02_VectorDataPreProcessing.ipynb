{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def getNumpyLoadTxt(pathFileName):\n",
    "\treturn np.loadtxt( pathFileName, delimiter=',', skiprows=1)\n",
    "def SaveArrayViaNumpy(path, data):\n",
    "    npd = np.asarray(data)\n",
    "    np.savetxt(path, npd, delimiter=\",\")\n",
    "    print('done for save!')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# data pre processing from CSV to numpy mat\n",
    "def MergeMatrixBasedOnSameClass(numpyList, classID):\n",
    "    numpyMat = numpyList[0]\n",
    "    for i in range(1, len(numpyList)):\n",
    "        numpyMat = np.concatenate((numpyMat, numpyList[i]), axis=0)\n",
    "    theShape = numpyMat.shape\n",
    "    numpyMat = np.insert(numpyMat, theShape[1], classID, axis=1)\n",
    "    return numpyMat\n",
    "def GetNumpyByShuffe(d):\n",
    "    np.random.shuffle(d)\n",
    "    return d\n",
    "def PreProcessRawCSV(d):\n",
    "    npMatList = []\n",
    "    for i in range(len(d)):\n",
    "        mergedD = MergeMatrixBasedOnSameClass(d[i], i)\n",
    "        npMatList.append(mergedD)\n",
    "    npMatAll = npMatList[0]\n",
    "    for i in range(1,len( npMatList)):\n",
    "        npMatAll = np.concatenate((npMatAll, npMatList[i]), axis=0)\n",
    "    return npMatAll\n",
    "def DataPreProcessing(d):\n",
    "    npMatAll = PreProcessRawCSV(d)\n",
    "    npData = GetNumpyByShuffe(npMatAll)\n",
    "    trainLength =  npData.shape[1]-1\n",
    "    XMat = npData[:,0:trainLength]\n",
    "    yMat = npData[:,trainLength]\n",
    "    return [XMat,yMat]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "circleRawBoth = []\n",
    "circleRawBoth.append(getNumpyLoadTxt('./data/vector/circleCSV/circle_01_DotArrayForTrainOrigin.csv'))\n",
    "circleRawBoth.append(getNumpyLoadTxt('./data/vector/circleCSV/circle_01_DotArrayForTrainSimplify.csv'))\n",
    "\n",
    "arrowRawBoth = []\n",
    "arrowRawBoth.append(getNumpyLoadTxt('./data/vector/arrowCSV/arrow_01_DotArrayForTrainOrigin.csv'))\n",
    "arrowRawBoth.append(getNumpyLoadTxt('./data/vector/arrowCSV/arrow_01_DotArrayForTrainSimplify.csv'))\n",
    "\n",
    "rectangleRawBoth = []\n",
    "rectangleRawBoth.append(getNumpyLoadTxt('./data/vector/rectangleCSV/rectangle_01_DotArrayForTrainOrigin.csv'))\n",
    "rectangleRawBoth.append(getNumpyLoadTxt('./data/vector/rectangleCSV/rectangle_01_DotArrayForTrainSimplify.csv'))\n",
    "\n",
    "textRawBoth = []\n",
    "textRawBoth.append(getNumpyLoadTxt('./data/vector/textCSV/text_01_DotArrayForTrainOrigin.csv'))\n",
    "textRawBoth.append(getNumpyLoadTxt('./data/vector/textCSV/text_01_DotArrayForTrainSimplify.csv'))\n",
    "\n",
    "trainRawBoth = [circleRawBoth,arrowRawBoth,rectangleRawBoth, textRawBoth]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "circleRawOrigin = []\n",
    "circleRawOrigin.append(getNumpyLoadTxt('./data/vector/circleCSV/circle_01_DotArrayForTrainOrigin.csv'))\n",
    "\n",
    "arrowRawOrigin = []\n",
    "arrowRawOrigin.append(getNumpyLoadTxt('./data/vector/arrowCSV/arrow_01_DotArrayForTrainOrigin.csv'))\n",
    "\n",
    "rectangleRawOrigin = []\n",
    "rectangleRawOrigin.append(getNumpyLoadTxt('./data/vector/rectangleCSV/rectangle_01_DotArrayForTrainOrigin.csv'))\n",
    "\n",
    "textRawOrigin = []\n",
    "textRawOrigin.append(getNumpyLoadTxt('./data/vector/textCSV/text_01_DotArrayForTrainOrigin.csv'))\n",
    "\n",
    "trainRawOrigin = [circleRawOrigin,arrowRawOrigin,rectangleRawOrigin, textRawOrigin]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "circleRawSimplify = []\n",
    "circleRawSimplify.append(getNumpyLoadTxt('./data/vector/circleCSV/circle_01_DotArrayForTrainSimplify.csv'))\n",
    "\n",
    "arrowRawSimplify = []\n",
    "arrowRawSimplify.append(getNumpyLoadTxt('./data/vector/arrowCSV/arrow_01_DotArrayForTrainSimplify.csv'))\n",
    "\n",
    "rectangleRawSimplify = []\n",
    "rectangleRawSimplify.append(getNumpyLoadTxt('./data/vector/rectangleCSV/rectangle_01_DotArrayForTrainSimplify.csv'))\n",
    "\n",
    "textRawSimplify = []\n",
    "textRawSimplify.append(getNumpyLoadTxt('./data/vector/textCSV/text_01_DotArrayForTrainSimplify.csv'))\n",
    "\n",
    "trainRawSimplify = [circleRawSimplify,arrowRawSimplify,rectangleRawSimplify, textRawSimplify]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# trainDATA = [trainRawOrigin,trainRawSimplify,trainRawBoth]\n",
    "trainDATA = [trainRawOrigin]       "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "done for save!\n"
     ]
    }
   ],
   "source": [
    "csv = PreProcessRawCSV(trainDATA[0])\n",
    "SaveArrayViaNumpy(\"./data/vector/dummy_smartDrawingTrainData.csv\", csv)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def OpenJson(path): \n",
    "    json_file = open(path , 'r')\n",
    "    json_str = json_file.read()\n",
    "    json_data = json.loads(json_str)\n",
    "    return json_data\n",
    "def GetListByShuffle(d):\n",
    "    from random import shuffle\n",
    "    shuffle(d)\n",
    "    return d\n",
    "def SaveArrayNumpy(path, data):\n",
    "    npd = np.asarray(data)\n",
    "    np.savetxt(path, npd, delimiter=\",\")\n",
    "    print('done for save!')\n",
    "def SplitData(d, classID):\n",
    "    outDot = []\n",
    "    outpos = []\n",
    "    index = 0\n",
    "    for i in d:\n",
    "        if(index % 2 == 0):\n",
    "            temp = [];\n",
    "            for j in d[i]:\n",
    "                temp.append(j)\n",
    "            temp.append(classID);\n",
    "            outDot.append(temp);\n",
    "        else:\n",
    "            temp = [];\n",
    "            for j in d[i]:\n",
    "                temp.append(j)\n",
    "            temp.append(classID);\n",
    "            outpos.append(temp);\n",
    "        index+=1\n",
    "    return outDot, outpos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "trainDataRaw = []\n",
    "trainDataRaw.append(OpenJson('./data/vector/TrainDataForCircle.json'))\n",
    "trainDataRaw.append(OpenJson('./data/vector/TrainDataForRect.json'))\n",
    "trainDataRaw.append(OpenJson('./data/vector/TrainDataForTri.json'))\n",
    "trainDataRaw.append(OpenJson('./data/vector/TrainDataHexagon.json'))\n",
    "trainDataRaw.append(OpenJson('./data/vector/TrainDataRandom.json'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "trainDataBeforeProcessing = []\n",
    "\n",
    "for i in range(len(trainDataRaw)):\n",
    "    outD, outPos= SplitData(trainDataRaw[i],i)\n",
    "    for j in outD:   \n",
    "        trainDataBeforeProcessing.append(j)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "done for save!\n"
     ]
    }
   ],
   "source": [
    "\n",
    "trainDataBeforeProcessing = GetListByShuffle(trainDataBeforeProcessing)\n",
    "SaveArrayNumpy(\"./data/vector/dummy_dataTrain.csv\", trainDataBeforeProcessing)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "npData = np.asarray(trainDataBeforeProcessing)\n",
    "npData.shape\n",
    "\n",
    "XMat = npData[:,range(npData.shape[1]-1)]\n",
    "yMat = npData[:,[npData.shape[1]-1]]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "XTrain = XMat[0:200]\n",
    "XTest = XMat[200:]\n",
    "\n",
    "yTrain = yMat[0:200]\n",
    "yTest = yMat[200:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "done for save!\n"
     ]
    }
   ],
   "source": [
    "trainDataRaw = []\n",
    "trainDataRaw.append(OpenJson('data/vector/TrainDataForCircle.json'))\n",
    "trainDataRaw.append(OpenJson('data/vector/TrainDataForRect.json'))\n",
    "trainDataRaw.append(OpenJson('data/vector/TrainDataForTri.json'))\n",
    "trainDataRaw.append(OpenJson('data/vector/TrainDataHexagon.json'))\n",
    "\n",
    "trainDataBeforeProcessing = []\n",
    "\n",
    "for i in range(len(trainDataRaw)):\n",
    "    outD, outPos= SplitData(trainDataRaw[i],i)\n",
    "    for j in outD:   \n",
    "        trainDataBeforeProcessing.append(j)\n",
    "trainDataBeforeProcessing = GetListByShuffle(trainDataBeforeProcessing)\n",
    "npData = np.asarray(trainDataBeforeProcessing)\n",
    "SaveArrayNumpy(\"./data/vector/dummy_dataTrainOnly4Class.csv\", trainDataBeforeProcessing)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.9.9 ('tf-gpu-2021')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.9 | packaged by conda-forge | (main, Dec 20 2021, 02:36:06) [MSC v.1929 64 bit (AMD64)]"
  },
  "vscode": {
   "interpreter": {
    "hash": "013cb43bc82c93deec78737468eebf90940d36d7ac13c74e2434686121b8a692"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
