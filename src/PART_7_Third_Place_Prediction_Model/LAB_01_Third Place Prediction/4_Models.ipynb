{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Third Place Report(Design, Data, AI) [V2022]\n",
    "### 2022 Version for Contribution to Architectural Institute of Korea\n",
    "### 제3 공간 분석과 적용 (디자인, 데이터, 인공지능), 대한건축학회 프로젝트 리포트 기고 버전\n",
    "\n",
    "##### [DaumBrunch Full Version](https://brunch.co.kr/@njnamju/148)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "-----\n",
    "* Inital research, [MIT Media Lab, City Science](https://www.media.mit.edu/groups/city-science/overview/) <br>\n",
    "  [Third Place Mobility Energy Consumption Per Person](http://www.njstudio.co.kr/main/project/2016_MobilityEnergyConsumptionMITMediaLab/index.html) <br>\n",
    "\n",
    "* Paper <br>\n",
    "  [Lee, N. (2021). Understanding and Analyzing the Characteristics of the Third Place in Urban Design: A Methodology for Discrete and Continuous Data in Environmental Design. In: Yuan, P.F., Yao, J., Yan, C., Wang, X., Leach, N. (eds) Proceedings of the 2020 DigitalFUTURES. CDRF 2020. Springer, Singapore](https://doi.org/10.1007/978-981-33-4400-6_11)  <br>\n",
    "  \n",
    "\n",
    "* Contribution <br> [대한건축학회 : Architectural Institute of Korea](https://www.aik.or.kr/)\n",
    "  제3 공간 분석과 적용 (디자인, 데이터, 인공지능)  <br> https://brunch.co.kr/@njnamju/148 <br>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "-----\n",
    "#### Author: NJ Namju Lee / nj.namju@gmail.com  \n",
    "###### * Linkedin - https://www.linkedin.com/in/nj-namju-lee-926b3252/    * Git - https://github.com/NamjuLee  \n",
    "\n",
    "###### * Web - http://www.njstudio.co.kr                                  * Lab - http://www.njslab.com/NJSLabCore/  \n",
    "\n",
    "###### * Video(English) - https://www.youtube.com/c/njnamjulee            * Writing(English) - https://medium.com/@nj-namju  \n",
    "\n",
    "###### * Video(Korean) - https://www.youtube.com/c/CodeforDesign          * Writing(Korean) - https://brunch.co.kr/@njnamju  \n",
    "-----"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 4. Training Models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4.1 Import data and process data for fitting models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(4273, 96)\n"
     ]
    }
   ],
   "source": [
    "dfDis = pd.read_csv('data/processed/google-third-place-Boston_DistanceClosest.csv')\n",
    "dfDis = dfDis.iloc[:, 1:]\n",
    "\n",
    "dataSetDis = dfDis.to_numpy()\n",
    "np.random.seed(222)\n",
    "np.random.shuffle(dataSetDis)\n",
    "X_dis = dataSetDis[:,:-1]\n",
    "y_dis = dataSetDis[:,-1:].flatten()\n",
    "\n",
    "dfDecay = pd.read_csv('data/processed/google-third-place-Boston_DecayClosest.csv')\n",
    "dfDecay = dfDecay.iloc[:, 1:]\n",
    "print(dfDecay.shape)\n",
    "\n",
    "dataSetDecay = dfDecay.to_numpy()\n",
    "np.random.seed(222)\n",
    "np.random.shuffle(dataSetDecay)\n",
    "X_decay = dataSetDecay[:,:-1]\n",
    "y_decay = dataSetDecay[:,-1:].flatten()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# https://scikit-learn.org/stable/modules/generated/sklearn.linear_model.LogisticRegression.html\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "XTrain_dis, XTest_dis, yTrain_dis, yTest_dis =train_test_split(X_dis, y_dis, test_size=0.2)\n",
    "std_scale = StandardScaler()\n",
    "std_scale.fit(XTrain_dis)\n",
    "XTrainStd_dis = std_scale.transform(XTrain_dis)\n",
    "XTestStd_dis  = std_scale.transform(XTest_dis)\n",
    "\n",
    "XTrain_decay, XTest_decay, yTrain_decay, yTest_decay =train_test_split(X_decay, y_decay, test_size=0.2)\n",
    "std_scale = StandardScaler()\n",
    "std_scale.fit(XTrain_decay)\n",
    "XTrainStd_decay = std_scale.transform(XTrain_decay)\n",
    "XTestStd_decay  = std_scale.transform(XTest_decay)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4.2 Logistic Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "shape:  (91, 95)\n",
      "coef: [[-3.80878434  2.10879781 -0.09920027 ... -0.63685661  0.26779251\n",
      "   0.19140878]\n",
      " [ 1.9473164  -5.59547751  0.0766282  ...  0.27132716 -0.35410094\n",
      "  -0.59983327]\n",
      " [ 0.20871056  0.19473616 -0.57842961 ...  0.15094114  0.09438069\n",
      "   0.25179084]\n",
      " ...\n",
      " [-0.76805817 -0.47794594 -0.16629085 ... -6.29332175 -1.15386821\n",
      "   1.69646368]\n",
      " [-0.11460645 -0.39936744 -0.0127533  ... -0.10222725 -5.12509915\n",
      "   0.16440904]\n",
      " [ 0.42681349 -0.88215166 -0.17873336 ...  0.68382575  0.78317262\n",
      "  -3.51671529]]\n",
      "intercept: [-1.99138982  0.24490494 -4.89468697 -4.57840931 -4.89508435  4.76577684\n",
      "  3.25014537  5.04223445  1.87641311 -4.89489743 -1.90450475  1.96766232\n",
      " -4.89483695 -4.89537603  5.35989589  1.41864382 -0.19365097 -4.89523889\n",
      " -4.89484305 -2.39703807  2.38176691  5.24327343 -4.89495089 -4.89498455\n",
      "  6.21965826  5.67139578  4.14189974 -4.89489739 -0.87685677 -0.10044901\n",
      "  4.86701338 -4.02822612  4.57790741 -0.36979121  0.10972515  1.28165903\n",
      "  5.7965909   0.00939465  3.30432065 -4.89486011 -4.89481138  3.2235178\n",
      "  3.6452954  -4.89494574  3.23192853 -4.89489228 -2.31593426  1.06642844\n",
      " -1.67734533  5.14418989  1.01987715  0.08720806  4.54300998  3.94322545\n",
      " -4.59166102  4.49730389  5.77500699  4.23205839  2.12055427 -0.32673392\n",
      " -2.42980313  1.11613521 -1.64188404 -4.89510367 -1.84618878  4.74653703\n",
      "  4.74311337 -4.89534366 -1.16318623 -4.89481844  2.15402193  0.16586253\n",
      " -4.89480824  1.66761319  4.91506508  0.28394699  4.81446635 -4.89554662\n",
      " -0.82961038  4.18232443 -3.98210277  2.6668022   5.719564   -0.82007375\n",
      " -0.59288133 -4.89505726 -4.89499216  0.95689457 -2.84466632 -0.89189831\n",
      " -3.0029715 ]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\namju\\miniconda3\\envs\\tf-gpu-2022\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:814: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    }
   ],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "lrL2_dis =  LogisticRegression(multi_class='multinomial', solver='lbfgs', penalty='none', random_state=2)\n",
    "lrL2_dis.fit(XTrainStd_dis, yTrain_dis)\n",
    "\n",
    "print('shape: ', lrL2_dis.coef_.shape)\n",
    "print('coef:', lrL2_dis.coef_)\n",
    "print('intercept:', lrL2_dis.intercept_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "shape:  (93, 95)\n",
      "coef: [[ 6.43848288e+00 -1.65287253e-01  2.83351597e-03 ...  1.17761368e-01\n",
      "   2.36220075e-03 -5.81784731e-02]\n",
      " [-5.25078992e-01  9.25610590e+00  9.70041526e-03 ...  1.00158674e-01\n",
      "  -2.01049984e-02 -2.53652438e-01]\n",
      " [-1.29200767e-02  4.38508332e-02  2.27013890e-01 ...  5.79630864e-02\n",
      "  -1.28720814e-02  7.45446025e-03]\n",
      " ...\n",
      " [ 6.77099821e-01  1.46043901e-01 -1.73646739e-02 ...  1.28368559e+01\n",
      "  -3.48459897e-02 -3.71908031e-01]\n",
      " [-1.76336857e-01 -6.26714985e-02  5.10548620e-02 ... -1.72153776e-01\n",
      "   6.95433549e+00 -8.20225346e-02]\n",
      " [-1.18107576e-01 -8.33749111e-02 -5.12475420e-02 ... -9.32418676e-02\n",
      "  -7.95171323e-02  5.27075894e+00]]\n",
      "intercept: [-1.47489405e+00 -3.02796258e-01 -1.94145647e+00 -1.92932303e+00\n",
      " -1.94141989e+00  3.55019056e+00  1.85421849e+00  3.52070407e+00\n",
      "  1.10570027e+00 -1.94149886e+00 -1.03648056e+00  3.00127855e-01\n",
      " -1.94142120e+00 -1.94146130e+00  5.32090677e+00 -8.86167269e-01\n",
      " -1.04135720e+00 -1.94144795e+00 -1.94144958e+00 -1.32433450e+00\n",
      " -3.20912705e-01  1.01189976e+00 -1.94144661e+00 -1.94145833e+00\n",
      "  2.92781034e+00  3.27229606e+00  1.84892591e+00 -1.94144199e+00\n",
      " -2.14277668e-01 -1.65391249e+00  1.98652018e+00 -1.66799248e+00\n",
      "  3.65576607e+00 -4.80615761e-01 -6.25291674e-01 -7.65349359e-01\n",
      "  6.83561075e+00 -1.64951758e+00  9.39458155e-01 -1.94153516e+00\n",
      " -1.94145808e+00 -7.68355176e-02  2.12320249e-01 -1.94143699e+00\n",
      "  2.24975977e+00 -1.99345131e+00 -1.94144843e+00 -9.55085782e-01\n",
      " -5.61786179e-01 -1.11433229e+00  1.34543768e+00  2.12007657e-01\n",
      "  2.74620596e-01 -2.72744033e-01  1.22521444e+00 -1.93617253e+00\n",
      "  1.41144769e+00  5.99649079e+00  3.11957267e+00  1.23251563e+00\n",
      " -9.24117398e-01 -1.47083413e+00 -7.17359973e-01 -1.48511694e+00\n",
      " -1.94144660e+00 -1.61613141e+00  6.32345422e+00  6.65336330e+00\n",
      " -1.94143756e+00 -1.16262396e+00 -1.94140445e+00 -6.46720911e-01\n",
      " -1.27633007e+00 -1.94144955e+00 -2.12432414e-01  6.37756942e+00\n",
      " -1.41851272e+00 -1.94145344e+00  4.06435561e-01 -1.94143449e+00\n",
      "  1.02915292e+00  1.56139057e+00 -1.98212921e+00  1.15933946e+00\n",
      "  5.16621414e+00 -1.44956475e+00 -6.24707570e-01 -1.94145680e+00\n",
      " -1.94145844e+00 -1.18204361e+00 -3.24360433e-03 -1.29744713e+00\n",
      " -1.62157380e+00]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\namju\\miniconda3\\envs\\tf-gpu-2022\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:814: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    }
   ],
   "source": [
    "lrL2_decay =  LogisticRegression(multi_class='multinomial', solver='lbfgs', penalty='none', random_state=2)\n",
    "lrL2_decay.fit(XTrainStd_decay, yTrain_decay)\n",
    "\n",
    "print('shape: ', lrL2_decay.coef_.shape)\n",
    "print('coef:', lrL2_decay.coef_)\n",
    "print('intercept:', lrL2_decay.intercept_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[27.  5. 50. 25. 69. 77. 56. 26. 80. 31. 22. 50. 86. 80. 31. 50. 22. 14.\n",
      " 37. 76. 83. 69. 86. 83. 77. 85. 50. 40. 37. 29. 69. 46. 55.  7. 77. 46.\n",
      " 68. 82. 44. 55. 25. 85. 21. 37. 40.  6. 59. 44. 69. 53. 37. 31. 67. 53.\n",
      " 16. 86. 86. 59. 59. 25.  7. 49. 58. 16. 29. 37. 26. 59. 69. 69. 85. 27.\n",
      " 46. 16. 16. 25. 25. 37. 50.  7. 14. 29. 36. 25. 16. 33. 82. 59.  7. 22.\n",
      " 86. 69. 25. 29. 92. 86.  6. 29. 64. 25. 56.  7. 27. 22. 69. 59. 80. 59.\n",
      " 31. 69. 68. 59. 16. 33. 25. 14. 86.  5. 69. 69. 31. 55. 73. 40. 86. 64.\n",
      "  7. 27. 82. 37. 36. 92.  1. 29. 46. 55. 86. 69. 91. 64. 46. 14.  7. 37.\n",
      " 59. 76. 56. 58. 56.  6. 29. 68. 31. 77. 21. 80. 69. 73. 68. 31. 33. 69.\n",
      " 82. 86. 92. 69. 26. 49.  7. 22. 77. 82. 49. 69. 56. 69. 83. 14. 85. 49.\n",
      " 50. 44. 37. 80. 59. 64. 44. 59. 50. 26. 25. 77. 76.  5. 59. 82. 37. 37.\n",
      " 53. 29. 16. 59. 49. 16. 80. 92. 85. 80. 50. 14. 33. 49. 86. 82. 59. 83.\n",
      " 59.  7. 22. 77. 69. 59. 69. 69. 92. 56. 31. 83. 33. 69. 74. 40.  7. 49.\n",
      " 59. 69. 80. 52. 77. 69. 46. 25. 25. 29. 50. 25. 29. 77. 21. 37. 69. 44.\n",
      " 21. 69. 86. 80. 25. 14. 64. 73. 36. 92. 77. 77. 31. 92.  5. 68. 21. 37.\n",
      " 25. 69. 22. 59.  7. 59. 59. 68. 25. 37. 58. 59. 60. 22. 60. 69. 92. 22.\n",
      " 37. 25. 92. 16. 86. 73. 37. 59. 25. 25. 14. 29. 46. 77. 80. 59. 74. 69.\n",
      " 37. 59. 31. 80. 29. 86. 68. 69. 76. 56. 50. 29. 31. 37. 58. 80. 31. 77.\n",
      " 53.  5. 80. 50.  7. 33. 69. 44. 31. 25. 77.  5. 14. 85.  8. 37. 50. 69.\n",
      " 52. 52. 29. 33. 86. 44. 37. 80.  5.  7. 85. 77. 80. 46. 30. 37. 77. 29.\n",
      "  8. 69. 86. 46. 37. 26. 59. 69. 26.  8. 92. 59. 53. 50. 92. 26. 29. 29.\n",
      " 69. 16. 82. 36. 31. 26. 86. 46. 31. 82. 22. 92. 59. 68. 80. 69. 92. 14.\n",
      " 69. 86. 82. 67. 37.  7. 77. 44. 76. 86. 69. 86. 77.  5. 92. 29. 77. 59.\n",
      " 25. 29. 69.  7. 68. 80. 86. 92. 31. 52.  7. 69. 33. 76. 59. 86. 40. 52.\n",
      " 37. 80. 35. 92. 16. 16. 69. 26. 68. 64.  7. 65. 25. 68. 29. 86. 64.  5.\n",
      " 29. 85.  5. 82. 69. 46.  7. 16. 83. 38. 80. 56. 40. 82. 25. 69. 25. 29.\n",
      " 69. 27. 69. 40. 59. 86. 25. 69.  7. 82. 56.  5.  5. 69. 92. 25. 25. 92.\n",
      " 22. 67. 27.  5. 69. 33. 59. 59. 68. 73.  7. 22. 56. 82.  7. 29. 69. 22.\n",
      " 31. 64. 27. 61. 77. 82. 94. 49. 83.  7. 37. 37. 31. 61. 68. 29. 37. 29.\n",
      " 46. 22. 80. 82.  8. 25. 50. 83. 29.  5. 25. 25. 59. 86. 80. 69. 25. 30.\n",
      " 77. 44. 16. 16. 77. 27.  6. 68.  7. 59. 59. 37. 77. 33. 64. 76. 56. 16.\n",
      " 29. 25. 29. 46. 37. 27. 27. 65. 46. 29. 43. 25. 22. 16. 80. 80. 82.  7.\n",
      " 43.  2. 59. 29. 82. 29. 68. 29. 86. 14. 25. 35.  7.  7. 53. 77. 37. 91.\n",
      " 59.  5. 40. 16. 56. 40. 22. 25. 86. 55.  8. 26. 69. 83. 77. 26.  7. 80.\n",
      " 25. 59. 92. 86. 27. 58. 50. 69. 14. 37.  7. 37. 46. 27. 25. 43. 37. 86.\n",
      " 22. 77. 37. 59. 16. 76. 86. 61. 50. 25. 77.  7. 50. 37. 43. 33. 86.  7.\n",
      " 92. 33.  6. 69. 25.  5. 69. 64. 77. 52. 37. 69. 69. 91. 29. 44. 43. 67.\n",
      " 29.  8. 76. 55. 62. 69. 73. 56. 52. 46. 31. 92. 26.  5. 69.  6. 69. 59.\n",
      " 40. 46. 59. 92. 69. 44.  5. 83. 69. 22. 25. 37. 27.  5. 22. 59. 29. 85.\n",
      " 69. 50.  2. 22.  6. 61. 56. 82. 59.  5. 92. 77. 25. 22.  7. 59. 31. 69.\n",
      " 36. 38. 21. 37. 76. 26. 59. 22. 74. 50. 25. 69. 52. 77. 86. 64. 80. 46.\n",
      " 83. 56. 29. 82.  8. 86. 80. 27. 40. 86. 73. 69.  7. 86. 49. 49. 69. 59.\n",
      " 29. 69. 49. 73.  5. 49. 64. 86.  8. 55. 86. 38. 22. 14. 37. 69. 85. 69.\n",
      " 82. 69. 86. 92. 92. 80. 69. 56. 73. 50. 29. 82. 60.  7. 77. 80. 82. 82.\n",
      " 46. 37. 61. 36.  6. 52. 64. 64. 46. 44. 44. 21. 50.  6. 46. 77. 68. 92.\n",
      " 31.  7. 92.  5. 27. 69. 21.  6. 52. 26. 82. 80. 69. 22. 59. 59. 65. 25.\n",
      " 46. 60. 59. 46. 69. 22. 78. 69. 37. 69. 59. 31. 61. 68. 29.  5. 77. 86.\n",
      " 14. 80. 68. 27. 29. 69. 27. 80. 59.]\n",
      "0.20701754385964913\n"
     ]
    }
   ],
   "source": [
    "# https://scikit-learn.org/stable/modules/generated/sklearn.linear_model.LogisticRegression.html\n",
    "\n",
    "from sklearn.metrics import precision_score\n",
    "from sklearn.metrics import confusion_matrix\n",
    "\n",
    "pred_logistic_dis = lrL2_dis.predict(XTestStd_dis)\n",
    "print(pred_logistic_dis)\n",
    "print(precision_score(yTest_dis, pred_logistic_dis,  average='micro'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[14. 60. 80. 34.  7. 49. 14. 69. 26. 31. 86. 29. 33. 43. 92. 37. 29. 33.\n",
      " 92. 33. 53. 27.  1. 60. 14. 22. 40. 55. 25. 82. 26. 64. 91. 50. 34. 25.\n",
      " 80. 61. 94. 60. 92. 30. 37. 22. 86. 16. 44. 83. 80. 87. 14. 46. 27. 31.\n",
      " 22. 80. 69. 69. 29. 25. 31. 25. 54. 73. 25. 61. 78. 80. 76. 26.  7. 43.\n",
      " 56. 49. 31. 52. 80. 52. 44. 76. 77. 25.  5. 59. 16. 25. 31. 44. 60. 80.\n",
      " 82. 64. 92. 76. 27. 46. 55. 64. 40. 26. 16. 68. 82. 46. 80. 31. 69. 69.\n",
      " 58.  7. 11. 46.  8.  5. 25. 92. 22. 76. 86. 25. 86. 22. 53. 58. 26. 73.\n",
      " 60. 49. 92. 92. 86. 14. 58.  5. 49. 50. 21. 27. 83. 30. 77. 46. 73. 94.\n",
      "  7. 69. 73. 52. 37. 60.  5. 43. 35. 46. 52. 77. 60. 43. 27. 46. 44. 80.\n",
      " 14. 44. 49. 50.  7. 16. 77. 21. 73. 76. 27. 73. 83. 37. 82. 50. 92. 92.\n",
      " 22.  1. 80. 33.  7. 31. 14. 56. 26. 50. 37. 27. 86. 31. 59. 85. 86. 46.\n",
      " 49. 44. 83. 85. 92.  8. 37. 26. 26. 46. 73. 16.  5. 46. 50. 29. 37.  5.\n",
      " 86. 52. 86. 68. 59. 35. 56. 73. 20. 80.  5. 31. 59. 69. 14. 92. 16. 34.\n",
      " 49. 27. 26. 69. 44. 86.  8. 46. 44. 59. 49. 69. 69. 80. 64. 69. 27. 78.\n",
      " 68. 61. 40.  7. 43. 49. 74. 92. 86. 26. 68. 49.  7. 56. 77. 49. 68. 21.\n",
      " 31. 69. 29. 80. 77. 35. 44. 16. 27. 21. 86. 92. 35. 29.  0. 68. 73.  5.\n",
      " 25. 60. 25. 49. 86. 65. 60. 77. 77. 77. 22. 92. 53. 17. 22. 60. 59. 25.\n",
      "  7. 37. 37. 68. 37. 33. 69. 59. 69.  7. 80. 46. 25. 86. 77. 29. 21. 60.\n",
      " 14. 25. 86.  8. 21. 60. 76. 69. 49. 31. 86.  0. 16. 46. 49. 86. 65. 46.\n",
      " 69. 73. 80. 55. 82. 22. 86. 25. 91.  6. 85. 76. 69. 14. 92. 52. 21. 68.\n",
      " 59. 64. 14. 44. 77. 40. 68. 22. 40. 16. 25. 92.  5. 82. 22. 76. 46. 51.\n",
      " 92. 37. 29. 40. 91. 49. 85. 86. 69. 14. 83. 44. 31.  6. 60. 69. 56. 37.\n",
      " 49. 33. 61. 86. 22. 31. 11. 40. 29.  6. 16. 77. 68. 68. 40. 37. 80.  5.\n",
      " 86.  1. 35. 56. 25. 44.  8. 14. 65. 73. 67. 92. 77. 35. 85. 46. 27.  8.\n",
      "  6. 26. 46. 46. 52.  7. 54. 16.  7. 76. 25. 67. 86. 22. 80. 86. 22. 49.\n",
      " 16. 69. 69. 43. 11. 59. 69. 22. 83. 80. 40. 40.  1. 46. 27.  5. 62. 31.\n",
      " 25. 46. 76. 31. 59. 49. 11. 59. 56. 26. 25. 37. 37.  5. 46. 37. 36. 56.\n",
      " 92. 14. 33. 60. 69. 44. 76. 61. 31. 17. 69. 52. 36.  6. 92. 29. 31. 22.\n",
      " 22. 25. 62. 76. 31. 84. 61. 94. 16. 16. 29. 61. 86. 25. 22. 44. 77. 80.\n",
      "  8. 73.  7. 60. 59. 43. 91. 86. 69. 80. 53. 21. 55. 52. 37. 33. 52. 53.\n",
      " 64. 22. 43. 58. 73. 91. 92. 29. 26. 87. 80. 56. 21. 49. 34. 86. 36. 86.\n",
      "  6. 37. 82. 59. 29. 53. 68. 33. 27. 17. 37. 31. 56. 37. 77. 76.  6. 26.\n",
      " 68. 33. 84.  7. 91. 77. 34. 77. 72. 40. 69. 33. 16. 80. 11. 68. 60. 43.\n",
      " 68. 93. 22. 43. 52. 68. 31. 22. 86. 49. 25. 59. 92. 74. 60. 77. 49. 61.\n",
      " 55. 69. 77. 73. 82. 69.  5. 86. 88. 69. 36. 69. 86. 22. 11. 60. 73. 40.\n",
      " 33. 14. 14. 49.  6. 92. 46. 37. 85. 86. 73. 77. 38. 31. 60. 40. 59. 27.\n",
      " 86. 64. 25. 69. 60. 61. 76.  8. 58. 22. 43. 22. 58. 54. 40. 44. 59. 22.\n",
      " 46. 80. 33. 58. 11. 60. 37. 14. 36. 92. 69. 86. 43. 77. 76. 29. 77. 74.\n",
      " 62.  8. 17. 58. 37. 59. 22. 60.  5. 26. 27. 40. 77. 55.  8. 74. 56. 46.\n",
      " 33. 55.  3. 85.  5.  8. 40. 37. 69. 29.  7. 80. 49.  5. 86.  8. 49. 27.\n",
      " 36. 59. 77. 17.  5.  5. 49. 59. 37. 31. 83. 80. 37. 93. 30. 77. 21. 68.\n",
      " 22. 86. 37. 14. 77. 14. 27. 82. 50. 43. 26. 64. 37. 60. 59. 56. 78. 40.\n",
      " 69. 60. 40. 22. 25. 50. 29. 37. 56. 14. 34. 53. 54. 86. 92. 29. 73. 83.\n",
      " 21. 14. 22. 31. 52. 43. 31. 25.  0. 14. 44. 22. 26. 31. 86. 77. 83.  8.\n",
      " 76. 68. 92. 77. 60. 27. 29. 59. 50. 92. 59.  7. 46. 43. 50. 73. 26. 62.\n",
      " 82. 31. 31. 36. 53. 92. 52. 25.  5. 31. 49. 82. 88. 46. 56. 74. 80. 22.\n",
      " 92. 68. 46. 26. 31. 52. 68. 25. 80. 69. 37. 59. 31. 77. 64. 59. 46. 33.\n",
      " 68. 29. 83. 92. 64. 85. 64. 83. 50.]\n",
      "0.41637426900584795\n"
     ]
    }
   ],
   "source": [
    "pred_logistic_decay = lrL2_decay.predict(XTestStd_decay)\n",
    "print(pred_logistic_decay)\n",
    "print(precision_score(yTest_decay, pred_logistic_decay,  average='micro'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[5.79654095e-08 4.74558711e-03 1.76808208e-09 ... 9.37451763e-02\n",
      "  1.93145602e-04 1.06479056e-06]\n",
      " [1.12182040e-06 2.33785302e-07 1.62814580e-09 ... 1.65607980e-01\n",
      "  1.08421736e-08 2.24323269e-08]\n",
      " [1.55231200e-05 2.08336820e-09 9.00719432e-11 ... 7.53577133e-10\n",
      "  9.72986369e-05 4.82602571e-11]\n",
      " ...\n",
      " [5.68902341e-08 5.45116969e-03 1.82387681e-09 ... 8.28208197e-02\n",
      "  1.93909865e-04 1.16722610e-06]\n",
      " [1.10735132e-06 2.53043344e-12 2.96845771e-11 ... 2.30386372e-10\n",
      "  3.98708693e-22 6.35256831e-09]\n",
      " [8.12586459e-06 1.15432943e-08 3.71677504e-09 ... 3.90177872e-09\n",
      "  1.34861322e-03 1.17774547e-08]]\n",
      "[[0 0 0 ... 0 0 0]\n",
      " [0 0 0 ... 0 0 0]\n",
      " [0 0 0 ... 0 0 0]\n",
      " ...\n",
      " [0 0 0 ... 8 0 0]\n",
      " [0 0 0 ... 0 0 0]\n",
      " [0 0 0 ... 0 0 0]]\n"
     ]
    }
   ],
   "source": [
    "print(lrL2_dis.predict_proba(XTestStd_dis))\n",
    "print(confusion_matrix(yTest_dis, pred_logistic_dis))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[2.16359753e-23 1.86140179e-24 1.76558933e-22 ... 3.18391857e-24\n",
      "  1.06840553e-23 3.45757717e-23]\n",
      " [7.04623746e-26 4.13779511e-19 4.88984933e-24 ... 3.61710326e-25\n",
      "  9.91549333e-27 1.12691078e-25]\n",
      " [6.21003320e-23 2.76711994e-21 4.36846674e-25 ... 1.80220207e-20\n",
      "  5.47754683e-23 3.20506341e-22]\n",
      " ...\n",
      " [1.35324309e-22 2.61964835e-20 1.56643979e-24 ... 1.39552506e-21\n",
      "  1.00638628e-21 1.90277723e-23]\n",
      " [1.04708169e-24 1.71812524e-24 5.67885520e-25 ... 2.57843680e-28\n",
      "  2.06149254e-24 4.06068010e-25]\n",
      " [4.19539847e-17 8.80513255e-22 5.78932629e-21 ... 2.35181785e-24\n",
      "  2.01746710e-19 6.50256724e-21]]\n",
      "[[ 3  0  0 ...  0  0  0]\n",
      " [ 0  1  0 ...  0  0  0]\n",
      " [ 0  0  0 ...  0  0  0]\n",
      " ...\n",
      " [ 0  0  0 ... 11  0  0]\n",
      " [ 0  0  0 ...  0  1  0]\n",
      " [ 0  0  1 ...  0  0  0]]\n"
     ]
    }
   ],
   "source": [
    "print(lrL2_decay.predict_proba(XTestStd_decay))\n",
    "print(confusion_matrix(yTest_decay, pred_logistic_decay))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([2.16359753e-23, 1.86140179e-24, 1.76558933e-22, 2.10122778e-22,\n",
       "       1.76410297e-22, 1.62433429e-21, 1.67946154e-19, 2.28544999e-21,\n",
       "       2.57421691e-24, 1.76731397e-22, 4.32469121e-22, 5.70836917e-21,\n",
       "       1.76415629e-22, 1.76578589e-22, 8.47080786e-01, 4.41534621e-24,\n",
       "       1.35648470e-17, 1.76524334e-22, 1.76530943e-22, 9.76191965e-21,\n",
       "       1.34767060e-20, 1.27715075e-20, 1.76518877e-22, 1.76566520e-22,\n",
       "       1.52919185e-01, 4.49890680e-20, 5.87452524e-17, 1.76500088e-22,\n",
       "       8.83926864e-20, 4.49929733e-23, 6.58917842e-19, 5.00206783e-23,\n",
       "       5.06262707e-18, 2.14683467e-21, 3.45184120e-21, 5.83841444e-25,\n",
       "       3.00018808e-19, 8.94540214e-23, 3.07955379e-21, 1.76879176e-22,\n",
       "       1.76565492e-22, 2.11637771e-24, 3.16611165e-18, 1.76479767e-22,\n",
       "       2.58163031e-25, 3.13793281e-22, 1.76526264e-22, 1.38767660e-23,\n",
       "       1.73611730e-22, 1.71094635e-23, 2.43642855e-08, 2.21425427e-16,\n",
       "       6.10328240e-23, 6.36229351e-17, 4.26660106e-09, 4.54352952e-22,\n",
       "       7.76302833e-20, 1.30100485e-22, 6.87561570e-20, 1.73734752e-18,\n",
       "       4.54942683e-23, 1.19732587e-23, 9.18455604e-25, 1.88177450e-22,\n",
       "       1.76518837e-22, 9.80071295e-23, 1.86812501e-24, 8.14782205e-23,\n",
       "       1.76482088e-22, 6.50822981e-24, 1.76347601e-22, 1.12206597e-25,\n",
       "       1.20256885e-22, 1.76530839e-22, 8.66297217e-26, 3.16944020e-24,\n",
       "       1.64398642e-23, 1.76546634e-22, 8.36624665e-21, 1.76469591e-22,\n",
       "       7.40029680e-24, 1.93781318e-23, 2.61512609e-22, 1.36650063e-24,\n",
       "       1.12406983e-12, 9.55394367e-23, 2.30528725e-23, 1.76560284e-22,\n",
       "       1.76566955e-22, 3.97868761e-24, 3.18391857e-24, 1.06840553e-23,\n",
       "       3.45757717e-23])"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "prob = lrL2_decay.predict_proba(XTestStd_decay)[0]\n",
    "prob"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4.3. SVM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "SVC(kernel='linear', random_state=2)"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# https://scikit-learn.org/stable/modules/generated/sklearn.svm.SVC.html\n",
    "from sklearn import svm \n",
    "\n",
    "lrSVM_dis = svm.SVC(kernel='linear', random_state=2)\n",
    "lrSVM_dis.fit(XTrainStd_dis, yTrain_dis)\n",
    "\n",
    "lrSVM_decay = svm.SVC(kernel='linear', random_state=2)\n",
    "lrSVM_decay.fit(XTrainStd_decay, yTrain_decay)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[92. 92. 86. 82. 92. 86. 26. 26. 43. 86. 73. 50. 86. 80. 86. 86. 25. 86.\n",
      " 37. 76. 77. 69. 37. 86. 77. 46. 50. 25. 37. 29. 69. 92. 55. 77. 69. 29.\n",
      " 68. 86. 86. 55. 59. 16. 21. 37. 25. 31. 59. 86. 69. 22. 37. 86. 59. 59.\n",
      " 16. 86. 43. 77. 59. 86. 26. 49. 58. 16. 49. 68. 82. 69. 69. 69. 46. 92.\n",
      " 49. 16. 16. 25. 25. 37. 50. 86. 46. 29. 36. 82. 16. 33. 37. 59. 59. 22.\n",
      " 86. 68. 86. 29. 92. 86. 29. 29. 64. 25. 85. 35. 27. 91. 64. 16. 21. 59.\n",
      " 31. 69. 68. 29. 16. 86. 59. 82. 37. 59. 69. 92. 31. 64. 73. 59. 86. 59.\n",
      " 59. 27. 86. 59. 36. 92. 26. 29. 22. 55. 86. 69. 37. 86. 22. 61. 86. 59.\n",
      " 59. 76. 26. 58. 69. 14. 29. 68. 31. 86. 21. 22. 49.  6. 69. 31. 82. 68.\n",
      " 82.  6. 33. 68. 76. 49. 82. 22. 82. 86. 49. 54. 56. 69. 83. 82. 86. 49.\n",
      " 86.  5. 37. 26. 59. 64. 44. 16. 86. 86. 59. 59. 76.  5. 59. 82. 59. 37.\n",
      " 59. 29. 16. 59. 49. 16. 49. 29. 85. 80. 50.  6. 82. 49. 77. 37. 59. 86.\n",
      " 25. 76. 59.  7. 69. 59. 29. 59. 92. 86. 86. 86. 55. 69. 92.  7. 59. 49.\n",
      " 59. 92. 22. 59. 59. 68. 29. 16. 25. 29. 25. 25. 49. 77.  8. 37. 69. 86.\n",
      " 21. 92. 86. 80. 25. 26. 37. 73. 77. 92. 69. 27. 40. 92.  7. 56. 21. 37.\n",
      " 25. 54. 86. 16. 26. 82. 46. 68. 25. 37. 69. 59. 59. 22. 43. 69. 92. 22.\n",
      " 59. 82. 33. 59. 43. 73. 59. 59. 43. 25. 33. 29. 46. 77. 80. 59. 46. 68.\n",
      " 37. 59.  7. 58. 29. 43. 68. 49. 59. 36. 69. 29. 86. 86. 58. 73. 43. 77.\n",
      " 22.  5. 80. 50. 35. 85. 49.  5. 31. 69. 29.  7. 82. 85.  8. 22. 86. 69.\n",
      " 52. 52. 29. 69. 52. 44. 25. 77.  5. 37. 16. 59. 36. 92. 16. 37. 77. 29.\n",
      " 58. 68. 86. 46. 25. 26.  7. 69. 86.  8. 29. 59. 59. 50. 29. 26. 29. 49.\n",
      " 68. 16. 82. 77. 78. 73. 86. 46. 27. 82.  6. 92. 59. 56. 80. 69. 92. 14.\n",
      " 69. 86. 82. 14. 68. 77. 77. 86. 76. 86. 69. 86. 77.  5. 92. 29. 77. 59.\n",
      "  7. 49. 69. 86. 68. 56. 86. 29.  5.  8.  5. 68. 37. 76. 59. 77. 59. 59.\n",
      " 37.  8. 59. 29. 77. 16. 29. 33. 86. 25.  5. 92. 55. 68. 29. 29. 64.  5.\n",
      " 29. 85. 46. 82. 69. 46. 76. 16. 86. 16. 22. 36. 25. 82. 44. 69. 52. 29.\n",
      " 69. 86. 69. 25. 59. 86. 25. 69.  5. 82.  7.  7. 86. 68. 29. 59. 59. 29.\n",
      " 59. 44. 44. 86. 54. 37. 60. 59. 68.  6. 59. 22. 56. 82. 59. 29.  7. 22.\n",
      "  5. 86. 44. 37. 69. 86. 80. 49. 83.  7. 56. 37.  5. 61. 68. 29. 37. 29.\n",
      " 29. 22. 80. 82. 40. 27. 25. 50. 46.  5.  5. 59. 59. 86. 82. 69. 25. 22.\n",
      " 77. 44. 16. 16. 77. 27.  6. 69. 60. 82. 59. 37. 69. 16. 64. 76. 56. 59.\n",
      " 29. 25. 49. 46. 37. 27. 92. 80. 46. 49. 43. 82. 22. 16. 80. 31. 86. 82.\n",
      " 43. 90. 26. 29. 37. 29. 68. 46. 86. 56. 25. 44. 82. 37. 59. 59. 25. 91.\n",
      " 59. 46. 59. 44. 56. 25. 25. 25. 86. 59.  8. 22. 69. 50. 69. 26. 92. 69.\n",
      " 25. 59. 92. 37.  5. 22.  8. 69. 14. 25. 16. 56. 21. 44. 82. 43. 37. 86.\n",
      " 22. 77. 61. 60. 16. 76.  6. 61. 50. 25. 69. 59. 86. 37. 73. 33. 86.  5.\n",
      " 29. 33. 14. 69.  7. 59. 92. 64. 82. 52. 37. 59.  7. 44. 29. 44. 43. 67.\n",
      " 29. 25. 76. 59.  7. 69.  6. 68. 52. 46. 86. 29. 26.  7. 69. 29. 69. 69.\n",
      " 25. 29. 59. 29. 69.  5.  7. 31. 92. 22. 25. 22. 27.  5. 22. 59. 29. 46.\n",
      " 68. 86. 90. 26.  6. 61. 29. 37. 37.  7. 92. 59. 44. 22. 77. 59. 22. 29.\n",
      " 36. 52. 21. 37. 59. 73. 59. 22. 46. 50. 44. 69. 52. 38. 86. 64. 43. 46.\n",
      " 25.  7. 49. 82.  8. 25. 92. 77. 73. 86. 25. 68. 33. 86. 49. 49. 69. 59.\n",
      " 29. 54. 49. 35.  5. 49. 37. 43. 58. 55. 86. 16. 22. 21. 37.  7. 85. 14.\n",
      " 82. 69. 86. 92. 29. 37. 69. 36.  6. 50. 29. 86. 49. 92. 77. 92. 82. 37.\n",
      " 46. 25. 22. 36. 29. 44. 37. 68. 46. 59. 44. 21. 50. 14. 92. 92. 56. 92.\n",
      " 86. 26. 29.  7. 92. 29. 52. 31. 59. 86. 82. 80. 92. 22. 59. 37. 92. 25.\n",
      " 46. 29. 59. 29. 68. 22. 82. 68. 37. 69. 59. 31. 26. 37. 29. 46. 77. 22.\n",
      "  6. 80. 86. 92. 29. 14. 92.  5. 60.]\n",
      "0.13099415204678364\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.metrics import confusion_matrix\n",
    "\n",
    "predSVM_dis = lrSVM_dis.predict(XTestStd_dis)\n",
    "print(predSVM_dis)\n",
    "print(accuracy_score(yTest_dis, predSVM_dis))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[14. 26. 80. 34.  7. 69. 14. 69. 26. 68. 86. 29. 33. 43. 92. 85. 29. 27.\n",
      " 92. 27. 53. 27.  1. 27. 29. 22. 26. 55. 25. 82. 26. 64. 91. 50. 82. 25.\n",
      " 80. 61. 94. 60. 92. 30. 16. 22. 86. 16. 17. 32. 80. 87. 14. 46. 27. 31.\n",
      " 43. 68. 68.  5. 29. 25.  5. 86. 83. 73. 25. 54. 78. 80. 76. 54. 29. 43.\n",
      " 56. 49. 31. 14. 80. 85. 44. 76. 77. 14.  7. 59. 16. 25. 31. 44. 60. 80.\n",
      " 37. 86. 92. 76. 60. 21. 55. 64. 26. 61. 86. 68. 91. 29. 80. 62. 33. 69.\n",
      " 58. 82. 11. 46.  8.  5. 14. 92. 22. 76. 31. 56. 44. 11. 53. 43. 54. 25.\n",
      " 49. 49. 92. 92. 31. 14. 43. 68. 49. 50. 21. 27. 76. 30. 91. 46. 86. 46.\n",
      "  7. 69. 73. 52. 37. 49.  5. 73. 35. 29. 68. 77. 26. 43. 27. 46. 27. 80.\n",
      "  7. 26. 49.  8.  7. 16. 77. 21. 73. 76. 27. 73. 14. 37. 37. 50. 92. 92.\n",
      " 22. 16. 80. 33.  7. 31. 14. 22. 26. 11. 25. 27. 86. 31. 50. 83. 11. 27.\n",
      " 49. 44. 83. 88. 92.  8. 37. 21. 74. 46. 73. 16.  5. 46. 11. 29. 77. 86.\n",
      " 86. 14. 82. 68. 59. 50. 33. 73. 83. 80.  5.  5. 59. 87. 59. 92. 16.  7.\n",
      " 49. 27. 26. 69.  5. 37.  8. 46. 44. 59. 49. 69. 69. 31. 64. 69. 27. 78.\n",
      " 68. 67. 40.  7. 43. 49. 74. 92. 86.  7. 77. 49.  7. 56. 59. 49. 68. 21.\n",
      " 31. 31. 44. 80. 77. 35.  8. 40. 27. 21. 86. 92. 35. 49.  0. 69. 73.  5.\n",
      " 25. 59. 25. 49. 86. 65. 59. 55. 86. 14. 22. 92. 53. 17. 22. 58. 93. 57.\n",
      "  7. 59. 37. 69. 37. 33. 69. 59. 33.  7. 80. 46. 25. 31. 77. 68. 21. 60.\n",
      " 30. 86. 31. 14. 21. 60. 76. 69. 49. 62. 86. 31. 16. 46. 49. 86. 65. 46.\n",
      " 31. 73. 80. 55. 82. 22. 86. 25. 86. 44. 17. 76. 69. 14. 27. 52. 21. 68.\n",
      " 59. 11. 14. 44. 77. 40. 68. 22. 40. 16.  6. 92. 68. 82. 22.  0. 46. 51.\n",
      " 65. 82. 29. 40. 91. 49. 31. 86. 69. 65. 83. 91. 31.  6. 60. 69. 56. 37.\n",
      " 49. 33. 61. 86. 22. 31. 11. 40. 68.  6. 73. 77. 68. 31. 40. 37. 80.  7.\n",
      " 86. 69. 46. 56. 25. 44.  8. 65. 65. 73. 67. 92. 37. 35. 85. 29. 27.  8.\n",
      " 46. 26. 29. 46. 73.  7. 54. 16.  7. 76. 25. 67. 67. 22. 80. 86. 22. 49.\n",
      " 16. 69. 69. 43. 76. 59. 94. 22. 83. 80. 40. 40.  1. 46. 46.  5. 62. 31.\n",
      " 25. 46. 76. 31. 59. 49. 11. 54. 56. 26. 25. 85. 37. 35. 46. 37. 21. 56.\n",
      " 92. 14. 46. 60. 69. 44. 71. 61. 83. 17. 69. 52. 36.  6. 92. 29.  7. 80.\n",
      " 22. 86.  7. 76. 31. 84. 61. 46. 16. 16. 29. 61. 86. 25. 22. 44. 14. 80.\n",
      "  8. 73.  5. 60. 59. 43. 91. 86. 69. 80.  8. 21. 85. 52. 77. 33. 73. 53.\n",
      " 64. 22. 67. 58. 86. 60. 29. 29. 26. 76. 92. 31. 21. 49. 34.  7. 36. 86.\n",
      "  6. 37. 82. 59. 29. 26. 68. 29. 27. 17. 46. 31. 46. 37. 77. 76.  6. 21.\n",
      " 14. 33. 69.  5. 91. 77. 69. 59. 90. 40. 31. 29. 55. 80. 11. 77. 26. 43.\n",
      " 68. 93. 22. 43. 52. 68. 83. 22. 86. 49. 37. 59. 92. 30. 59. 37. 49. 11.\n",
      " 50. 69. 77. 74. 82. 69.  5. 86. 88. 69. 36. 69. 31. 22. 77. 60. 73. 40.\n",
      " 68. 14. 14. 49.  6. 92. 46. 37. 16. 86. 68. 33. 38. 68. 60. 26. 59. 54.\n",
      " 86. 64. 25. 69. 49. 37. 76.  8. 59. 22. 43. 22. 58. 54. 22. 16. 14. 22.\n",
      " 46. 80. 33. 58. 11. 60. 37. 77. 36. 92. 69. 86. 43. 77. 76. 29. 53. 73.\n",
      " 25. 30. 62. 58. 37. 59. 22. 60.  5. 26. 27. 26. 11. 55.  8. 74. 22. 29.\n",
      " 59. 55. 69. 64.  5.  8. 40. 37. 69. 29.  7. 80. 49. 37. 86.  8. 69. 27.\n",
      " 36.  6. 82. 17.  5.  5. 49. 50. 37. 31. 83. 80. 16. 93. 30. 33. 21. 68.\n",
      " 22. 86. 37. 14. 77. 14.  5. 82. 31. 43. 26. 64. 37. 44. 55. 56. 78. 40.\n",
      " 92. 14. 22. 22. 25. 11. 29. 14. 52. 59.  7. 27. 54. 86. 27. 29. 73. 83.\n",
      " 21. 14. 22. 31. 50. 43. 67. 25. 50. 86. 44. 22. 26. 31. 86. 77. 32. 37.\n",
      " 76. 68. 92. 77. 60. 27. 49. 59. 50. 11. 59.  5. 46. 43. 11. 73. 26. 62.\n",
      " 60. 26. 64. 36. 53. 92. 25. 25.  5. 31. 49. 82. 88. 29. 31. 74. 46. 22.\n",
      " 92. 68. 46. 26. 31. 52. 77. 25. 80. 69. 37. 59. 31. 58. 64. 26. 21. 33.\n",
      " 68. 29. 83. 11. 64. 16. 64. 83.  6.]\n",
      "0.3111111111111111\n"
     ]
    }
   ],
   "source": [
    "predSVM_decay = lrSVM_decay.predict(XTestStd_decay)\n",
    "print(predSVM_decay)\n",
    "print(accuracy_score(yTest_decay, predSVM_decay))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 0  0  0 ...  0  0  0]\n",
      " [ 0  0  0 ...  1  0  0]\n",
      " [ 0  0  0 ...  0  0  0]\n",
      " ...\n",
      " [ 0  0  0 ... 12  0  0]\n",
      " [ 0  0  0 ...  0  0  0]\n",
      " [ 0  0  0 ...  0  0  0]]\n"
     ]
    }
   ],
   "source": [
    "print(confusion_matrix(yTest_dis, predSVM_dis))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "-----\n",
    "### References & Useful links\n",
    "\n",
    "Lee, N. (2021). Understanding and Analyzing the Characteristics of the Third Place in Urban Design: A Methodology for Discrete and Continuous Data in Environmental Design. In: Yuan, P.F., Yao, J., Yan, C., Wang, X., Leach, N. (eds) Proceedings of the 2020 DigitalFUTURES. CDRF 2020. Springer, Singapore. https://doi.org/10.1007/978-981-33-4400-6_11\n",
    "\n",
    "\n",
    "\n",
    "Oldenburg, R., Brissett, (1982). D.: The third place. Qual. Sociol. 5(4), 265–284\n",
    "\n",
    "\n",
    "\n",
    "Lee, Namju. (2022). Computational Design, Seoul, Bookk, https://brunch.co.kr/@njnamju/144\n",
    "\n",
    "\n",
    "\n",
    "Lee, Namju, (2022). Discrete Urban Space and Connectivity, https://nj-namju.medium.com/discrete-urban-space-and-connectivity-492b3dbd0a81\n",
    "\n",
    "\n",
    "\n",
    "Woo. Junghyun, (2022). Numeric Network Analysis for Pedestrians, https://axuplatform.medium.com/0-numeric-network-analysis-47a2538e636c\n",
    "\n",
    "\n",
    "\n",
    "Lee, Namju, (2022). Computational Design Thinking for Designers, https://nj-namju.medium.com/computational-design-thinking-for-designers-68224bb07f5c\n",
    "\n",
    "\n",
    "\n",
    "Lee, Namju. (2016). Third Place Mobility Energy Consumption Per Person, http://www.njstudio.co.kr/main/project/2016_MobilityEnergyConsumptionMITMediaLab \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.9.12 ('tf-gpu-2022')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  },
  "vscode": {
   "interpreter": {
    "hash": "72bc0f943a863b7fcc9ff0d11405a78faecbd3bfafd8f122065908abfcb424a6"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
